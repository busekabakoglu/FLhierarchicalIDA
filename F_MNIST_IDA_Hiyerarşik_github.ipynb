{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "F-MNIST  IDA - Hiyerarşik github",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/busekabakoglu/FLhierarchicalIDA/blob/main/F_MNIST_IDA_Hiyerar%C5%9Fik_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKgyXytzUNIj"
      },
      "source": [
        "# !pip install syft\n",
        "#import syft # send olayini yapacak\n",
        "import json\n",
        "import os\n",
        "import gc\n",
        "import collections\n",
        "import numpy as np   # tf icin lazim\n",
        "import tensorflow as tf \n",
        "import copy \n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "import math\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Cw8mzKMtnT"
      },
      "source": [
        "num_clients = 10\n",
        "batch_size = 20\n",
        "learning_rate = 0.01\n",
        "decay_rate = 0.995\n",
        "local_epochs = 1\n",
        "federated_rounds = 300\n",
        "checkpoint_path = \"checkpoint.ckpt\"\n",
        "saving_frequency = 1\n",
        "is_balanced = True\n",
        "load_weights = False\n",
        "current_epoch = {}\n",
        "if os.path.exists(\"current_epoch.json\"):\n",
        "  with open('current_epoch.json') as json_file:\n",
        "    data = json.load(json_file)\n",
        "    current_epoch = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHGAl5IDG7xK"
      },
      "source": [
        "class Utilities:\n",
        "  @staticmethod\n",
        "  def add(model1, model2):\n",
        "    temp = np.multiply(model1, 0)\n",
        "    for i in range(len(model2)):\n",
        "        temp[i] = np.add(model1[i], model2[i])\n",
        "    return temp\n",
        "\n",
        "  @staticmethod\n",
        "  def subtract(model1, model2):\n",
        "    temp = np.multiply(model1, 0)\n",
        "    for i in range(len(model2)):\n",
        "        temp[i] = np.subtract(model1[i], model2[i] )\n",
        "    return temp\n",
        "\n",
        "  @staticmethod\n",
        "  def divide(model, number):\n",
        "    temp = np.multiply(model, 0)\n",
        "    for i in range(len(model)):\n",
        "        temp[i] = model[i]/number\n",
        "    return temp\n",
        "\n",
        "  @staticmethod\n",
        "  def flatten_weights(weights):\n",
        "    flat_ = []\n",
        "    for layer in weights:\n",
        "      flat_ = tf.concat([flat_, tf.reshape(layer , [-1, ]) ] , axis=0)\n",
        "    return flat_\n",
        "\n",
        "  @staticmethod\n",
        "  def find_avg_model(client_models, num_clients):\n",
        "    num_clients = num_clients * 1.0\n",
        "    total = np.multiply(client_models[0], 0)\n",
        "    for model in client_models:\n",
        "      total = Utilities.add(total, model)\n",
        "    return Utilities.divide(total, num_clients)\n",
        "\n",
        "  @staticmethod\n",
        "  def ida_normalization_factor(client_models, avg_model):\n",
        "    # Z = np.multiply( avg_model , 0 )\n",
        "    Z = 0.0\n",
        "    for model in client_models:\n",
        "      # temp = np.multiply( avg_model , 0 )\n",
        "      # Going through all layers of the model\n",
        "      diff = Utilities.subtract(avg_model, model)\n",
        "      distance = tf.norm(Utilities.flatten_weights(diff), ord=1)\n",
        "      inv_distance = np.divide(1.0, distance)\n",
        "      Z = np.add(Z, inv_distance)\n",
        "      \n",
        "    return Z\n",
        "  \n",
        "  @staticmethod\n",
        "  def ida_coefficient_of_model(client_model, avg_model, Z ):\n",
        "    #sub = np.multiply(avg_model, 0.0)\n",
        "    diff = Utilities.subtract(avg_model, client_model)\n",
        "    distance = tf.norm(Utilities.flatten_weights(diff) , ord=1)\n",
        "    inv_distance = np.divide(1.0, distance)\n",
        "    inv_distance = np.divide(inv_distance, Z)\n",
        "    return inv_distance\n",
        "\n",
        "  @staticmethod\n",
        "  def all_ida_coefficients(client_models, avg_model, Z ):\n",
        "    coeffs = []\n",
        "    for model in  client_models:\n",
        "      coeffs.append( Utilities.ida_coefficient_of_model( model , avg_model , Z ) )\n",
        "    return coeffs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1da2G96x2jV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5e21b6-1371-4cb7-90a6-441cccf017ba"
      },
      "source": [
        "# Buse Version\n",
        "# train_x = np.load(\"./mimic_benchmark/X_train.npy\")\n",
        "# train_y = np.load(\"./mimic_benchmark/y_train.npy\")\n",
        "# test_x = np.load(\"./mimic_benchmark/X_test.npy\")\n",
        "# test_y = np.load(\"./mimic_benchmark/y_test.npy\")\n",
        "\n",
        "# Barış Version\n",
        "# train_x = np.load(\"./drive/My Drive/X_train.npy\")\n",
        "# train_y = np.load(\"./drive/My Drive/y_train.npy\")\n",
        "# test_x = np.load(\"./drive/My Drive/X_test.npy\")\n",
        "# test_y = np.load(\"./drive/My Drive/y_test.npy\")\n",
        "\n",
        "fmnist_train, fmnist_test = tf.keras.datasets.fashion_mnist.load_data()\n",
        "train_x, train_y = fmnist_train  # global \n",
        "test_x, test_y = fmnist_test     # global  (x, y)\n",
        "train_x = train_x / 255.0\n",
        "test_x  = test_x  / 255.0 \n",
        "train_x = train_x.reshape((train_x.shape[0], 28, 28, 1))\n",
        "test_x = test_x.reshape((test_x.shape[0], 28, 28, 1))\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000,)\n",
            "(10000, 28, 28, 1)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rpg02or2jYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff3dc1ed-79f8-4661-9315-fe15ceed2758"
      },
      "source": [
        "num_train_data_point = len(train_y) # global\n",
        "INPUT_SHAPE = train_x.shape[1:]\n",
        "print(INPUT_SHAPE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vY9Mq2Q2jbD"
      },
      "source": [
        "# Shuffles 2 arrays side by side\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "# For example we have 10 clients\n",
        "# We have to distribute the data to these clients\n",
        "\n",
        "\n",
        "# Balanced Case Using All of the Data (No reuse)\n",
        "def split_data(distribution_type, num_clients, data_amount = 600):\n",
        "  if distribution_type == \"BALANCED\":\n",
        "    return getBalancedData(num_clients)\n",
        "  elif distribution_type == \"IMBALANCED\":\n",
        "    return get_imbalanced_data(num_clients)\n",
        "  elif distribution_type == \"FIXED_SIZE_BALANCED_DATA\":\n",
        "    return get_fixed_amount_balanced_data(num_clients, data_amount)\n",
        "  elif distribution_type == \"SKEWED\":\n",
        "    return get_skewed_data(num_clients, data_amount)\n",
        "  elif distribution_type == \"IMBALANCED_AND_SKEWED\":\n",
        "    return get_imbalanced_and_skewed_data(num_clients, data_amount)\n",
        "\n",
        "def getBalancedData( num_clients ):\n",
        "  x,y = unison_shuffled_copies(train_x, train_y)\n",
        "  new_x = np.array_split(x, num_clients)\n",
        "  new_y = np.array_split(y, num_clients)  \n",
        "  return new_x, new_y\n",
        "\n",
        "# Imbalanced and Skewed Data\n",
        "def get_imbalanced_and_skewed_data(num_clients, data_amount = 60000):\n",
        "  train_index_list = [[], [], [], [], [], [], [], [], [], []]\n",
        "  new_x = []\n",
        "  new_y = []\n",
        "  for i, v in enumerate(train_y):\n",
        "    train_index_list[v].append(i)\n",
        "\n",
        "  for i in range(num_clients):\n",
        "    cur_x, cur_y = make_split_train_data_by_number(i, train_index_list, np.random.randint(1, high=len(train_index_list[i]), dtype=int))\n",
        "    new_x.append(cur_x)\n",
        "    new_y.append(cur_y)\n",
        "\n",
        "  return new_x, new_y\n",
        "\n",
        "# Skewed Distribution\n",
        "def get_skewed_data(num_clients, max_size):\n",
        "  train_index_list = [[], [], [], [], [], [], [], [], [], []]\n",
        "  new_x = []\n",
        "  new_y = []\n",
        "  for i, v in enumerate(train_y):\n",
        "    train_index_list[v].append(i)\n",
        "  \n",
        "  for i in range(len(train_index_list)):\n",
        "    print(len(train_index_list[i]))\n",
        "\n",
        "  for i in range(num_clients):\n",
        "    cur_x = []\n",
        "    cur_y = []\n",
        "    for index in train_index_list[i]:\n",
        "      cur_x.append(train_x[index])\n",
        "      cur_y.append(train_y[index])\n",
        "    #cur_x, cur_y = (make_split_train_data_by_number(i, train_index_list, max_size))\n",
        "    new_x.append(np.array(cur_x))\n",
        "    new_y.append(np.array(cur_y))\n",
        "\n",
        "  return new_x, new_y\n",
        " \n",
        "def make_split_train_data_by_number(index_number, train_index_list, size=600):\n",
        "    if index_number != -1 :\n",
        "        random_index = np.random.randint(0, high=len(train_index_list[index_number]), size=min(size, len(train_index_list[index_number])))\n",
        "        s_train_x = []\n",
        "        s_train_y = []\n",
        "        for v in random_index:\n",
        "            s_train_x.append(train_x[train_index_list[index_number][v]])\n",
        "            s_train_y.append(train_y[train_index_list[index_number][v]])\n",
        "        return s_train_x, s_train_y\n",
        "    else:\n",
        "        return train_x, train_y\n",
        "\n",
        "# Balanced data \n",
        "def get_fixed_amount_balanced_data(num_clients, data_amount):\n",
        "  x,y = unison_shuffled_copies(train_x, train_y)\n",
        "  x = x[:num_clients*data_amount]\n",
        "  y = y[:num_clients*data_amount]\n",
        "  new_x = np.array_split(x, num_clients)\n",
        "  new_y = np.array_split(y, num_clients)  \n",
        "  return new_x, new_y\n",
        "\n",
        "# Imbalanced Data Distribution\n",
        "def get_imbalanced_data(num_clients):\n",
        "  random_data_amounts = np.random.randint(1, high=num_train_data_point//num_clients, size=num_clients, dtype=int)\n",
        "  print(random_data_amounts)\n",
        "  x,y = unison_shuffled_copies(train_x, train_y)\n",
        "  start = 0\n",
        "  new_x = []\n",
        "  new_y = []\n",
        "  for amount in random_data_amounts:\n",
        "    end = start + amount\n",
        "    current_x = x[start:end]\n",
        "    current_y = y[start:end]\n",
        "    start = end\n",
        "    new_x.append(current_x)\n",
        "    new_y.append(current_y)\n",
        "  return new_x, new_y\n",
        "\n",
        "# To be used for splitting the data\n",
        "#fed_x , fed_y = getBalancedData(num_clients)\n",
        "# fed_x , fed_y = split_data(\"BALANCED\", num_clients)\n",
        "# fed_x = np.array(fed_x)\n",
        "# fed_y = np.array(fed_y)\n",
        "# for y in fed_y:\n",
        "#   print(len(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKzPRICD2jdZ"
      },
      "source": [
        "def getModel():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Conv2D(\n",
        "                                  filters= 6,\n",
        "                                  kernel_size = (5,5),\n",
        "                                  strides=(1,1),\n",
        "                                  activation='tanh',\n",
        "                                  input_shape=INPUT_SHAPE))\n",
        "  \n",
        "  model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2),\n",
        "                                          strides=(2,2)))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(\n",
        "                                  filters=16,\n",
        "                                  kernel_size = (5,5),\n",
        "                                  strides=(1,1),\n",
        "                                  activation='tanh'))\n",
        "  \n",
        "  model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2),\n",
        "                                          strides=(2,2)))\n",
        "  \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  \n",
        "  model.add(tf.keras.layers.Dense(units=120,activation='tanh'))\n",
        "  \n",
        "  model.add(tf.keras.layers.Dense(units=84,activation='tanh'))\n",
        "    \n",
        "  model.add(tf.keras.layers.Dense(units=10,activation='softmax'))\n",
        "  return model\n",
        "\n",
        "def visualize_metrics(metrics, Loss=True):\n",
        "      # Get training and test loss histories\n",
        "  count = 0\n",
        "  acc = metrics[\"acc\"]\n",
        "  loss = metrics[\"loss\"]\n",
        "  \n",
        "  # # Create count of the number of epochs\n",
        "  epoch_count = range(1, len(acc) + 1)\n",
        "  # Visualize loss history\n",
        "  if Loss:\n",
        "    plt.subplot(2,1,1)\n",
        "    plt.plot(epoch_count, loss, 'r--')\n",
        "    plt.legend(['Training Loss'])\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "  plt.subplot(2,1,2)\n",
        "  plt.plot(epoch_count, acc, 'b--')\n",
        "  plt.legend(['Accuracy'])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Acc')\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BibHjSC-J2V"
      },
      "source": [
        "class Client():\n",
        "  def __init__(self, id, x, y):\n",
        "    self.id = id\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.amount_of_data = len(y)\n",
        "    self.model = getModel()\n",
        "    self.old_model = []\n",
        "  def init_session(self, global_model):\n",
        "    self.model.set_weights( global_model )\n",
        "\n",
        "  def train_client( self, learning_rate, batch_size, local_epochs, global_model ):\n",
        "    #old_model = np.array( self.model.get_weights(), dtype=object )\n",
        "    updated_model = copy.deepcopy(global_model) \n",
        "    self.model.set_weights( updated_model )\n",
        "    optimizer = tf.keras.optimizers.SGD( lr=learning_rate )\n",
        "    self.model.compile( loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"] )\n",
        "    self.model.fit( self.x, self.y, epochs=local_epochs, batch_size=batch_size, shuffle=True, verbose=1 )\n",
        "    new_model = np.array( self.model.get_weights() , dtype=object )\n",
        "    #gradients = np.subtract( new_model , old_model )\n",
        "    return new_model\n",
        "\n",
        "class EdgeServer():\n",
        "  def __init__( self, client_list, client_indexes, global_model):\n",
        "    self.client_list = client_list\n",
        "    self.client_indexes = client_indexes\n",
        "    self.gradients = np.multiply( np.array(global_model ,dtype=object), 0 )\n",
        "    self.model_weights = np.array(global_model ,dtype=object)\n",
        "    self.num_clients = len(client_indexes)\n",
        "    self.history = {\"loss\" : [], \"acc\" :[], \"prec\" :[] , \"recall\" : [] }\n",
        "    self.model = getModel()\n",
        "    \n",
        "  \n",
        "  def train_slaves(self, learning_rate, batch_size, local_epochs, edge_interval, global_interval): # :)\n",
        "    for round in range(global_interval):\n",
        "      returned_models_total = np.multiply(self.gradients, 0)\n",
        "      client_models = []\n",
        "\n",
        "      for client in self.client_list:\n",
        "        client_model =  client.train_client(learning_rate, batch_size, edge_interval, self.model_weights)\n",
        "        returned_models_total = np.add( returned_models_total, client_model ) \n",
        "        client_models.append(client_model)\n",
        "\n",
        "      avg_model = np.divide( returned_models_total , self.num_clients )\n",
        "      Z = Utilities.ida_normalization_factor(client_models, avg_model)\n",
        "      ida_factors = Utilities.all_ida_coefficients(client_models, avg_model, Z)\n",
        "      weighted_total_client_models = np.multiply(self.gradients, 0)\n",
        "\n",
        "      for i in range(len(client_models)):\n",
        "        weighted_total_client_models = np.add(weighted_total_client_models, np.multiply( client_models[i] , ida_factors[i] ) )\n",
        "\n",
        "      self.model_weights = weighted_total_client_models\n",
        "\n",
        "      self.model.set_weights(self.model_weights)\n",
        "\n",
        "      optimizer = tf.keras.optimizers.SGD(lr=learning_rate)\n",
        "      self.model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\", \n",
        "               tf.keras.metrics.AUC(curve='PR', multi_label=True),\n",
        "               tf.keras.metrics.AUC(curve=\"ROC\"),\n",
        "               tf.keras.metrics.Precision(top_k=1),\n",
        "               tf.keras.metrics.Recall(top_k=1),\n",
        "               tf.keras.metrics.FalseNegatives(),\n",
        "               tf.keras.metrics.FalsePositives(),\n",
        "               ])\n",
        "      \n",
        "      self.model.evaluate( test_x , test_y )\n",
        "      self.history['loss'].append(current_state[0])\n",
        "      self.history['acc'].append(current_state[1])\n",
        "      self.history[\"prec\"].append(current_state[2])\n",
        "      self.history[\"recall\"].append(current_state[3])\n",
        "\n",
        "      return self.model_weights\n",
        "    \n",
        "class Server():\n",
        "  def __init__(self, num_clients, num_edge_servers, distribution, edge_interval, global_interval, load_weights=False, visualization_freq=30 ):\n",
        "    self.history = {\"loss\" : [], \"acc\" :[] }\n",
        "    self.model = getModel()\n",
        "    self.num_clients = num_clients\n",
        "    self.num_edge_servers = num_edge_servers\n",
        "    self.gradients = np.multiply( np.array(self.model.get_weights() ,dtype=object), 0 )\n",
        "    self.clients = []\n",
        "    self.edge_servers = []\n",
        "    self.visualization_freq = visualization_freq\n",
        "    self.curr_epoch = 0\n",
        "    self.distribution = distribution\n",
        "    self.edge_interval = edge_interval\n",
        "    self.global_interval = global_interval\n",
        "    self.init_clients()\n",
        "    self.init_edge_servers()\n",
        "\n",
        "  def train_slave_masters(self, learning_rate, batch_size, local_epochs, edge_interval, global_interval, federated_rounds, decay_rate):\n",
        "    # self.init_clients()\n",
        "    # self.init_edge_servers()\n",
        "\n",
        "    for round in range(federated_rounds):\n",
        "      returned_models = np.multiply(self.gradients, 0)\n",
        "      edge_models = [] \n",
        "      if round % 4 == 0 :\n",
        "        self.clear_backend()\n",
        "      \n",
        "      for edge_server in self.edge_servers: \n",
        "        edge_model = edge_server.train_slaves(learning_rate, batch_size, local_epochs, edge_interval, global_interval) \n",
        "        returned_models = np.add(returned_models, edge_model)\n",
        "        edge_models.append(edge_model)\n",
        "      \n",
        "      avg_model = np.divide( returned_models, len(self.edge_servers) )\n",
        "      Z = Utilities.ida_normalization_factor(edge_models, avg_model)\n",
        "      ida_factors = Utilities.all_ida_coefficients(edge_models, avg_model, Z)\n",
        "      updated_model = np.multiply(self.gradients, 0)\n",
        "      for i in range(len(edge_models)):\n",
        "        updated_model = np.add(updated_model, np.multiply( edge_models[i] , ida_factors[i] ) )\n",
        "      self.model.set_weights(updated_model)\n",
        "      optimizer = tf.keras.optimizers.SGD(lr=learning_rate)\n",
        "      self.model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "      print(\"\"\".... EPOCH {} DONE ....\"\"\".format(round))\n",
        "      current_state = self.model.evaluate( train_x, train_y )\n",
        "      self.model.evaluate( test_x , test_y )\n",
        "      self.history['loss'].append(current_state[0])\n",
        "      self.history['acc'].append(current_state[1])\n",
        "      if round != 0 and round % self.visualization_freq == 0 : \n",
        "        visualize_metrics(self.history)\n",
        "      learning_rate = learning_rate  * decay_rate\n",
        "      \n",
        "  def init_clients(self):\n",
        "    weight_factors = []\n",
        "    total_data = 0\n",
        "    for i in range(self.num_clients):\n",
        "      self.clients.append( Client( i, fed_x[ i ], fed_y[ i ] ) )\n",
        "    \n",
        "    initial_model = np.array( self.model.get_weights(), dtype=object )\n",
        "    for client in self.clients:\n",
        "      client.init_session(initial_model)\n",
        "      #burda niye amount of data eklemişiz :\n",
        "      # FedAvg'dan kalma,  Gerek yok aslinda ama zararı da yok bundan sonraki 2 satırın\n",
        "      weight_factors.append(client.amount_of_data)\n",
        "      total_data += client.amount_of_data\n",
        "    self.weight_factors = np.array(weight_factors) / float(total_data)\n",
        "\n",
        "  def init_edge_servers(self):\n",
        "    edge = self.num_edge_servers\n",
        "    client_number = self.num_clients//self.num_edge_servers\n",
        "    for i in range(self.num_edge_servers):\n",
        "      self.edge_servers.append( EdgeServer( [], [], self.model.get_weights() ) )\n",
        "    for i in range(self.num_clients):\n",
        "      edge_index = i//client_number\n",
        "      self.edge_servers[edge_index].client_list.append(self.clients[i])\n",
        "      self.edge_servers[edge_index].client_indexes.append(i)\n",
        "      self.edge_servers[edge_index].num_clients += 1\n",
        "    print( \"... EDGE SERVERS INITIALIZED ...\" )\n",
        "      \n",
        "  \n",
        "\n",
        "  def clear_backend(self):\n",
        "    print(\"CLEARING BACKEND....\")\n",
        "    saved_weights = self.model.get_weights() \n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "    self.model.set_weights(saved_weights)\n",
        "    del self.clients\n",
        "    self.clients = []\n",
        "    del self.edge_servers\n",
        "    self.edge_servers = []\n",
        "    self.init_clients()\n",
        "    self.init_edge_servers() \n",
        "    # for client in self.clients:\n",
        "      # client.model.set_weights(saved_weights)\n",
        "    print(\"BACKEND CLEARED!\")\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV8rZdfXM8Qe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "254fa354-a184-4f65-bce2-bced66618273"
      },
      "source": [
        "# BALANCED CASE\n",
        "distribution = \"BALANCED\"\n",
        "fed_x , fed_y = split_data(distribution, num_clients)\n",
        "fed_x = np.array(fed_x)\n",
        "fed_y = np.array(fed_y)\n",
        "\n",
        "server1 = Server( num_clients, 2, distribution, edge_interval=1, global_interval=3, load_weights=False, visualization_freq=30)\n",
        "# server1.model.summary()\n",
        "server1.train_slave_masters(learning_rate, batch_size, local_epochs, 2, 3, 50, decay_rate)\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(lr=learning_rate)\n",
        "server1.model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"TEST SET EVALUATION\")\n",
        "print(server1.model.evaluate(test_x , test_y))\n",
        "visualize_metrics(server1.history)\n",
        "\n",
        "print(\"HISTORY : \")\n",
        "print(server1.model.history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "... EDGE SERVERS INITIALIZED ...\n",
            "CLEARING BACKEND....\n",
            "... EDGE SERVERS INITIALIZED ...\n",
            "BACKEND CLEARED!\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.9582 - accuracy: 0.3442\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.0148 - accuracy: 0.6711\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.9652 - accuracy: 0.3276\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.0128 - accuracy: 0.6691\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.9583 - accuracy: 0.3164\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.0134 - accuracy: 0.6683\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.9524 - accuracy: 0.3462\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.0111 - accuracy: 0.6623\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.9694 - accuracy: 0.3175\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.0322 - accuracy: 0.6673\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.9488 - accuracy: 0.3428\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.0085 - accuracy: 0.6555\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.9696 - accuracy: 0.3481\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.0420 - accuracy: 0.6518\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.9846 - accuracy: 0.3195\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.0190 - accuracy: 0.6632\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.9545 - accuracy: 0.3533\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.0153 - accuracy: 0.6577\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.9566 - accuracy: 0.3359\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.0053 - accuracy: 0.6636\n",
            ".... EPOCH 0 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.8583 - accuracy: 0.7050\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8732 - accuracy: 0.7012\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.8408 - accuracy: 0.6996\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7486 - accuracy: 0.7289\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.8458 - accuracy: 0.6942\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7701 - accuracy: 0.7156\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.8291 - accuracy: 0.7037\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7451 - accuracy: 0.7289\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.8389 - accuracy: 0.6969\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7484 - accuracy: 0.7171\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.8276 - accuracy: 0.7061\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7415 - accuracy: 0.7276\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.8399 - accuracy: 0.6999\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7361 - accuracy: 0.7273\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.8483 - accuracy: 0.6921\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7487 - accuracy: 0.7248\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.8320 - accuracy: 0.7053\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7504 - accuracy: 0.7289\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.8145 - accuracy: 0.7186\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7423 - accuracy: 0.7304\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.8327 - accuracy: 0.7109\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7349 - accuracy: 0.7384\n",
            ".... EPOCH 1 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.7063 - accuracy: 0.7358\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7271 - accuracy: 0.7274\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7051 - accuracy: 0.7356\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6672 - accuracy: 0.7497\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7290 - accuracy: 0.7243\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6896 - accuracy: 0.7373\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6877 - accuracy: 0.7433\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6752 - accuracy: 0.7491\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7270 - accuracy: 0.7307\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6505 - accuracy: 0.7545\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7239 - accuracy: 0.7251\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6687 - accuracy: 0.7391\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 0.6864 - accuracy: 0.7361\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6685 - accuracy: 0.7479\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7057 - accuracy: 0.7293\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6629 - accuracy: 0.7439\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.7410\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6743 - accuracy: 0.7462\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6999 - accuracy: 0.7353\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6549 - accuracy: 0.7559\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6907 - accuracy: 0.7401\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6357 - accuracy: 0.7656\n",
            ".... EPOCH 2 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6397 - accuracy: 0.7599\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6628 - accuracy: 0.7508\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6431 - accuracy: 0.7603\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6153 - accuracy: 0.7706\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6540 - accuracy: 0.7523\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6284 - accuracy: 0.7705\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6431 - accuracy: 0.7530\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6375 - accuracy: 0.7574\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6593 - accuracy: 0.7484\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6255 - accuracy: 0.7633\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6540 - accuracy: 0.7529\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6125 - accuracy: 0.7710\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6229 - accuracy: 0.7560\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6068 - accuracy: 0.7670\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6403 - accuracy: 0.7529\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6445 - accuracy: 0.7511\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6382 - accuracy: 0.7584\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6373 - accuracy: 0.7563\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6387 - accuracy: 0.7576\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6148 - accuracy: 0.7677\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6140 - accuracy: 0.7685\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6046 - accuracy: 0.7718\n",
            ".... EPOCH 3 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5990 - accuracy: 0.7749\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6242 - accuracy: 0.7659\n",
            "CLEARING BACKEND....\n",
            "... EDGE SERVERS INITIALIZED ...\n",
            "BACKEND CLEARED!\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6150 - accuracy: 0.7651\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6227 - accuracy: 0.7672\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6310 - accuracy: 0.7657\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6054 - accuracy: 0.7693\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6148 - accuracy: 0.7734\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5980 - accuracy: 0.7758\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6195 - accuracy: 0.7646\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5987 - accuracy: 0.7741\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6128 - accuracy: 0.7681\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5812 - accuracy: 0.7823\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6023 - accuracy: 0.7628\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5631 - accuracy: 0.7825\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6159 - accuracy: 0.7625\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5698 - accuracy: 0.7785\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6317 - accuracy: 0.7631\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5817 - accuracy: 0.7801\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.6153 - accuracy: 0.7644\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5727 - accuracy: 0.7851\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5988 - accuracy: 0.7813\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5488 - accuracy: 0.7988\n",
            ".... EPOCH 4 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5679 - accuracy: 0.7882\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5944 - accuracy: 0.7794\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5664 - accuracy: 0.7925\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5626 - accuracy: 0.7901\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5688 - accuracy: 0.7903\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5589 - accuracy: 0.7922\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5723 - accuracy: 0.7805\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5756 - accuracy: 0.7873\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5680 - accuracy: 0.7918\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5546 - accuracy: 0.7909\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5660 - accuracy: 0.7949\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5581 - accuracy: 0.7917\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5615 - accuracy: 0.7794\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5438 - accuracy: 0.7863\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5914 - accuracy: 0.7772\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5563 - accuracy: 0.7850\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5608 - accuracy: 0.7821\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5503 - accuracy: 0.7882\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5872 - accuracy: 0.7748\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5718 - accuracy: 0.7818\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5666 - accuracy: 0.7975\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5471 - accuracy: 0.8009\n",
            ".... EPOCH 5 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5443 - accuracy: 0.7986\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5712 - accuracy: 0.7864\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5528 - accuracy: 0.7950\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5313 - accuracy: 0.8036\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5543 - accuracy: 0.7887\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5490 - accuracy: 0.7950\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5658 - accuracy: 0.7862\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5598 - accuracy: 0.7924\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5491 - accuracy: 0.7979\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5335 - accuracy: 0.8052\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5477 - accuracy: 0.7927\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5414 - accuracy: 0.7997\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5387 - accuracy: 0.7974\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5357 - accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5721 - accuracy: 0.7870\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5514 - accuracy: 0.7867\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5447 - accuracy: 0.7938\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5371 - accuracy: 0.7974\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5407 - accuracy: 0.7954\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5256 - accuracy: 0.8074\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5347 - accuracy: 0.8027\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5393 - accuracy: 0.7990\n",
            ".... EPOCH 6 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5240 - accuracy: 0.8084\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5520 - accuracy: 0.7970\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5315 - accuracy: 0.8070\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5138 - accuracy: 0.8109\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5551 - accuracy: 0.7938\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5457 - accuracy: 0.7949\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5660 - accuracy: 0.7839\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5488 - accuracy: 0.8005\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.8060\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5120 - accuracy: 0.8108\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5141 - accuracy: 0.8094\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5320 - accuracy: 0.8006\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5280 - accuracy: 0.7984\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5157 - accuracy: 0.8079\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5352 - accuracy: 0.7937\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5414 - accuracy: 0.7960\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5306 - accuracy: 0.8068\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5256 - accuracy: 0.8081\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5360 - accuracy: 0.7989\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5400 - accuracy: 0.7999\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5163 - accuracy: 0.8142\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5141 - accuracy: 0.8186\n",
            ".... EPOCH 7 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5076 - accuracy: 0.8140\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5373 - accuracy: 0.8018\n",
            "CLEARING BACKEND....\n",
            "... EDGE SERVERS INITIALIZED ...\n",
            "BACKEND CLEARED!\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5138 - accuracy: 0.8109\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5007 - accuracy: 0.8177\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5449 - accuracy: 0.7907\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5237 - accuracy: 0.8089\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5221 - accuracy: 0.8141\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5240 - accuracy: 0.8134\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5350 - accuracy: 0.7962\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5036 - accuracy: 0.8188\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5089 - accuracy: 0.8076\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.8147\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5027 - accuracy: 0.8073\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4997 - accuracy: 0.8146\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5051 - accuracy: 0.8139\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5018 - accuracy: 0.8130\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5110 - accuracy: 0.8095\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5247 - accuracy: 0.8050\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5078 - accuracy: 0.8117\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7993\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4947 - accuracy: 0.8192\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4908 - accuracy: 0.8239\n",
            ".... EPOCH 8 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4928 - accuracy: 0.8226\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5224 - accuracy: 0.8114\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4984 - accuracy: 0.8218\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4905 - accuracy: 0.8186\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5094 - accuracy: 0.8117\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4861 - accuracy: 0.8257\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5091 - accuracy: 0.8101\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5155 - accuracy: 0.8088\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5090 - accuracy: 0.8218\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4883 - accuracy: 0.8218\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5007 - accuracy: 0.8161\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5192 - accuracy: 0.8026\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5021 - accuracy: 0.8010\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4543 - accuracy: 0.8307\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4926 - accuracy: 0.8184\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4847 - accuracy: 0.8239\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4952 - accuracy: 0.8171\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5024 - accuracy: 0.8163\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5030 - accuracy: 0.8066\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4754 - accuracy: 0.8226\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4797 - accuracy: 0.8224\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4811 - accuracy: 0.8276\n",
            ".... EPOCH 9 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4801 - accuracy: 0.8289\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5109 - accuracy: 0.8164\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4928 - accuracy: 0.8224\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4941 - accuracy: 0.8162\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5001 - accuracy: 0.8142\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4804 - accuracy: 0.8155\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5028 - accuracy: 0.8076\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4982 - accuracy: 0.8166\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5131 - accuracy: 0.8134\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4773 - accuracy: 0.8304\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4939 - accuracy: 0.8196\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4691 - accuracy: 0.8269\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4618 - accuracy: 0.8281\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4590 - accuracy: 0.8291\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4889 - accuracy: 0.8122\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4897 - accuracy: 0.8161\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5118 - accuracy: 0.8132\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4691 - accuracy: 0.8237\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4926 - accuracy: 0.8225\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4970 - accuracy: 0.8214\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4825 - accuracy: 0.8245\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4673 - accuracy: 0.8309\n",
            ".... EPOCH 10 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4686 - accuracy: 0.8332\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4997 - accuracy: 0.8209\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4855 - accuracy: 0.8325\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4638 - accuracy: 0.8334\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.5025 - accuracy: 0.8202\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4666 - accuracy: 0.8291\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4828 - accuracy: 0.8210\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4730 - accuracy: 0.8194\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4923 - accuracy: 0.8208\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4790 - accuracy: 0.8315\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4823 - accuracy: 0.8257\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4669 - accuracy: 0.8324\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4679 - accuracy: 0.8210\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4279 - accuracy: 0.8434\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4777 - accuracy: 0.8221\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4613 - accuracy: 0.8280\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4872 - accuracy: 0.8281\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4975 - accuracy: 0.8153\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4663 - accuracy: 0.8250\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4579 - accuracy: 0.8388\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4667 - accuracy: 0.8428\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4679 - accuracy: 0.8315\n",
            ".... EPOCH 11 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4587 - accuracy: 0.8360\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4896 - accuracy: 0.8243\n",
            "CLEARING BACKEND....\n",
            "... EDGE SERVERS INITIALIZED ...\n",
            "BACKEND CLEARED!\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4876 - accuracy: 0.8300\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4561 - accuracy: 0.8446\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4691 - accuracy: 0.8294\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4751 - accuracy: 0.8277\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4761 - accuracy: 0.8257\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4712 - accuracy: 0.8309\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4561 - accuracy: 0.8360\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4774 - accuracy: 0.8384\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4517 - accuracy: 0.8296\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4554 - accuracy: 0.8301\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4630 - accuracy: 0.8221\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4532 - accuracy: 0.8314\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4649 - accuracy: 0.8261\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4543 - accuracy: 0.8221\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4641 - accuracy: 0.8311\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4569 - accuracy: 0.8368\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4480 - accuracy: 0.8383\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4523 - accuracy: 0.8319\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4772 - accuracy: 0.8341\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4448 - accuracy: 0.8441\n",
            ".... EPOCH 12 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4494 - accuracy: 0.8409\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4816 - accuracy: 0.8260\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4456 - accuracy: 0.8448\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4501 - accuracy: 0.8421\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4627 - accuracy: 0.8391\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4585 - accuracy: 0.8366\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4747 - accuracy: 0.8303\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4528 - accuracy: 0.8271\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4699 - accuracy: 0.8286\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4705 - accuracy: 0.8266\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4672 - accuracy: 0.8230\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4513 - accuracy: 0.8296\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4315 - accuracy: 0.8401\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4258 - accuracy: 0.8435\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4716 - accuracy: 0.8241\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4501 - accuracy: 0.8338\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4531 - accuracy: 0.8356\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4605 - accuracy: 0.8345\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.8431\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4539 - accuracy: 0.8353\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4306 - accuracy: 0.8440\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4313 - accuracy: 0.8423\n",
            ".... EPOCH 13 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4395 - accuracy: 0.8449\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4720 - accuracy: 0.8302\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4735 - accuracy: 0.8350\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4357 - accuracy: 0.8451\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4748 - accuracy: 0.8238\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4285 - accuracy: 0.8454\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4466 - accuracy: 0.8411\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4330 - accuracy: 0.8473\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4605 - accuracy: 0.8309\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4476 - accuracy: 0.8395\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4527 - accuracy: 0.8311\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4279 - accuracy: 0.8346\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4405 - accuracy: 0.8375\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4126 - accuracy: 0.8479\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4336 - accuracy: 0.8382\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4468 - accuracy: 0.8322\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4580 - accuracy: 0.8313\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4471 - accuracy: 0.8332\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4632 - accuracy: 0.8272\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4484 - accuracy: 0.8368\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4581 - accuracy: 0.8387\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4387 - accuracy: 0.8487\n",
            ".... EPOCH 14 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4309 - accuracy: 0.8469\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4637 - accuracy: 0.8327\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4313 - accuracy: 0.8545\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4290 - accuracy: 0.8438\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4293 - accuracy: 0.8465\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.8384\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4505 - accuracy: 0.8407\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4468 - accuracy: 0.8374\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4481 - accuracy: 0.8419\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4464 - accuracy: 0.8389\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 3ms/step - loss: 0.4626 - accuracy: 0.8345\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4267 - accuracy: 0.8414\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4147 - accuracy: 0.8388\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4261 - accuracy: 0.8390\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4560 - accuracy: 0.8310\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4316 - accuracy: 0.8368\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4413 - accuracy: 0.8396\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4292 - accuracy: 0.8426\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4336 - accuracy: 0.8417\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4287 - accuracy: 0.8470\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4502 - accuracy: 0.8412\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4121 - accuracy: 0.8539\n",
            ".... EPOCH 15 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4243 - accuracy: 0.8485\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4566 - accuracy: 0.8346\n",
            "CLEARING BACKEND....\n",
            "... EDGE SERVERS INITIALIZED ...\n",
            "BACKEND CLEARED!\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4298 - accuracy: 0.8435\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4306 - accuracy: 0.8497\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4535 - accuracy: 0.8345\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4350 - accuracy: 0.8453\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4556 - accuracy: 0.8317\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4262 - accuracy: 0.8474\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4339 - accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4485 - accuracy: 0.8361\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4478 - accuracy: 0.8381\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4284 - accuracy: 0.8483\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4314 - accuracy: 0.8396\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4053 - accuracy: 0.8507\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4420 - accuracy: 0.8373\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4381 - accuracy: 0.8334\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4331 - accuracy: 0.8413\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4167 - accuracy: 0.8470\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4324 - accuracy: 0.8486\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4194 - accuracy: 0.8504\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4002 - accuracy: 0.8565\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4138 - accuracy: 0.8527\n",
            ".... EPOCH 16 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4169 - accuracy: 0.8520\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4504 - accuracy: 0.8395\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4179 - accuracy: 0.8500\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4158 - accuracy: 0.8575\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4231 - accuracy: 0.8449\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4551 - accuracy: 0.8363\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 0.4367 - accuracy: 0.8468\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4411 - accuracy: 0.8361\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4327 - accuracy: 0.8403\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4368 - accuracy: 0.8421\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4165 - accuracy: 0.8466\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4387 - accuracy: 0.8405\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4183 - accuracy: 0.8428\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4006 - accuracy: 0.8551\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4182 - accuracy: 0.8436\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4209 - accuracy: 0.8440\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4280 - accuracy: 0.8434\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4351 - accuracy: 0.8423\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4176 - accuracy: 0.8493\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4221 - accuracy: 0.8443\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4145 - accuracy: 0.8549\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4116 - accuracy: 0.8536\n",
            ".... EPOCH 17 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4109 - accuracy: 0.8542\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4442 - accuracy: 0.8412\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4272 - accuracy: 0.8485\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4152 - accuracy: 0.8513\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4092 - accuracy: 0.8554\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4058 - accuracy: 0.8437\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4085 - accuracy: 0.8498\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4374 - accuracy: 0.8488\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4358 - accuracy: 0.8363\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4232 - accuracy: 0.8436\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4324 - accuracy: 0.8471\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4213 - accuracy: 0.8504\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4035 - accuracy: 0.8532\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3815 - accuracy: 0.8557\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4138 - accuracy: 0.8469\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3924 - accuracy: 0.8548\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4213 - accuracy: 0.8538\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4276 - accuracy: 0.8511\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4183 - accuracy: 0.8493\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4144 - accuracy: 0.8501\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4013 - accuracy: 0.8591\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3928 - accuracy: 0.8607\n",
            ".... EPOCH 18 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4039 - accuracy: 0.8560\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4379 - accuracy: 0.8436\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4126 - accuracy: 0.8540\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.8576\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4278 - accuracy: 0.8479\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4161 - accuracy: 0.8584\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4318 - accuracy: 0.8487\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4113 - accuracy: 0.8510\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4187 - accuracy: 0.8451\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4022 - accuracy: 0.8550\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4350 - accuracy: 0.8398\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3993 - accuracy: 0.8599\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3860 - accuracy: 0.8608\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3934 - accuracy: 0.8538\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4185 - accuracy: 0.8494\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4144 - accuracy: 0.8444\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4192 - accuracy: 0.8472\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4132 - accuracy: 0.8525\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4042 - accuracy: 0.8511\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3863 - accuracy: 0.8555\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3894 - accuracy: 0.8635\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3965 - accuracy: 0.8585\n",
            ".... EPOCH 19 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3984 - accuracy: 0.8585\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4325 - accuracy: 0.8451\n",
            "CLEARING BACKEND....\n",
            "... EDGE SERVERS INITIALIZED ...\n",
            "BACKEND CLEARED!\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4180 - accuracy: 0.8495\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3942 - accuracy: 0.8608\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4201 - accuracy: 0.8542\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3967 - accuracy: 0.8567\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4217 - accuracy: 0.8473\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4172 - accuracy: 0.8468\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4069 - accuracy: 0.8446\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4066 - accuracy: 0.8541\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4159 - accuracy: 0.8463\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4003 - accuracy: 0.8511\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4071 - accuracy: 0.8471\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3775 - accuracy: 0.8622\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3945 - accuracy: 0.8565\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3921 - accuracy: 0.8553\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4116 - accuracy: 0.8561\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4047 - accuracy: 0.8490\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4039 - accuracy: 0.8463\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3913 - accuracy: 0.8603\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4169 - accuracy: 0.8487\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3863 - accuracy: 0.8666\n",
            ".... EPOCH 20 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3930 - accuracy: 0.8606\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4273 - accuracy: 0.8461\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3981 - accuracy: 0.8609\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4023 - accuracy: 0.8613\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4046 - accuracy: 0.8536\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3912 - accuracy: 0.8612\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4133 - accuracy: 0.8495\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3865 - accuracy: 0.8632\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4129 - accuracy: 0.8498\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3943 - accuracy: 0.8595\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4352 - accuracy: 0.8367\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4053 - accuracy: 0.8549\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3941 - accuracy: 0.8538\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3932 - accuracy: 0.8603\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3947 - accuracy: 0.8570\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3804 - accuracy: 0.8650\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4145 - accuracy: 0.8460\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3925 - accuracy: 0.8566\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4059 - accuracy: 0.8527\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3891 - accuracy: 0.8558\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3885 - accuracy: 0.8599\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4002 - accuracy: 0.8530\n",
            ".... EPOCH 21 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3880 - accuracy: 0.8621\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4223 - accuracy: 0.8480\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4091 - accuracy: 0.8567\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3967 - accuracy: 0.8569\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3997 - accuracy: 0.8550\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4121 - accuracy: 0.8550\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3910 - accuracy: 0.8534\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4001 - accuracy: 0.8542\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4129 - accuracy: 0.8499\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4077 - accuracy: 0.8614\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4239 - accuracy: 0.8429\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3794 - accuracy: 0.8587\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3702 - accuracy: 0.8648\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3669 - accuracy: 0.8553\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3873 - accuracy: 0.8620\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3852 - accuracy: 0.8604\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3947 - accuracy: 0.8550\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3892 - accuracy: 0.8613\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4105 - accuracy: 0.8509\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4126 - accuracy: 0.8520\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3899 - accuracy: 0.8654\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3732 - accuracy: 0.8701\n",
            ".... EPOCH 22 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3846 - accuracy: 0.8626\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4200 - accuracy: 0.8496\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3949 - accuracy: 0.8637\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4054 - accuracy: 0.8600\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3901 - accuracy: 0.8596\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3874 - accuracy: 0.8670\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4105 - accuracy: 0.8571\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4013 - accuracy: 0.8560\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3952 - accuracy: 0.8559\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3999 - accuracy: 0.8609\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4117 - accuracy: 0.8512\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3998 - accuracy: 0.8599\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3867 - accuracy: 0.8509\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3730 - accuracy: 0.8636\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 3s 4ms/step - loss: 0.3894 - accuracy: 0.8540\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3828 - accuracy: 0.8612\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3965 - accuracy: 0.8545\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3881 - accuracy: 0.8620\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3896 - accuracy: 0.8584\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3883 - accuracy: 0.8569\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4078 - accuracy: 0.8479\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3954 - accuracy: 0.8591\n",
            ".... EPOCH 23 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3792 - accuracy: 0.8639\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4141 - accuracy: 0.8513\n",
            "CLEARING BACKEND....\n",
            "... EDGE SERVERS INITIALIZED ...\n",
            "BACKEND CLEARED!\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3757 - accuracy: 0.8624\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4071 - accuracy: 0.8586\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4032 - accuracy: 0.8562\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3915 - accuracy: 0.8598\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4208 - accuracy: 0.8549\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4185 - accuracy: 0.8489\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4045 - accuracy: 0.8502\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3764 - accuracy: 0.8656\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3908 - accuracy: 0.8579\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3954 - accuracy: 0.8524\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3809 - accuracy: 0.8625\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3742 - accuracy: 0.8576\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3718 - accuracy: 0.8688\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3754 - accuracy: 0.8623\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3813 - accuracy: 0.8625\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3816 - accuracy: 0.8605\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3896 - accuracy: 0.8514\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3859 - accuracy: 0.8575\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3778 - accuracy: 0.8647\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3664 - accuracy: 0.8667\n",
            ".... EPOCH 24 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3743 - accuracy: 0.8668\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4106 - accuracy: 0.8524\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3867 - accuracy: 0.8587\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3817 - accuracy: 0.8636\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3904 - accuracy: 0.8581\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3802 - accuracy: 0.8644\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3877 - accuracy: 0.8644\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3900 - accuracy: 0.8630\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3884 - accuracy: 0.8570\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3834 - accuracy: 0.8578\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3878 - accuracy: 0.8552\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3856 - accuracy: 0.8673\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3797 - accuracy: 0.8639\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3801 - accuracy: 0.8580\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3848 - accuracy: 0.8635\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3620 - accuracy: 0.8663\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3928 - accuracy: 0.8535\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3738 - accuracy: 0.8602\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4025 - accuracy: 0.8477\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3837 - accuracy: 0.8647\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3688 - accuracy: 0.8684\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3668 - accuracy: 0.8674\n",
            ".... EPOCH 25 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3716 - accuracy: 0.8659\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4075 - accuracy: 0.8533\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3961 - accuracy: 0.8667\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3846 - accuracy: 0.8624\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4038 - accuracy: 0.8589\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4014 - accuracy: 0.8554\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3820 - accuracy: 0.8648\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.8602\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.4054 - accuracy: 0.8546\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8681\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3985 - accuracy: 0.8545\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3851 - accuracy: 0.8592\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3716 - accuracy: 0.8662\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3681 - accuracy: 0.8651\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3997 - accuracy: 0.8557\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3775 - accuracy: 0.8576\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3875 - accuracy: 0.8602\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3733 - accuracy: 0.8654\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3954 - accuracy: 0.8531\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3868 - accuracy: 0.8563\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3743 - accuracy: 0.8620\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3862 - accuracy: 0.8655\n",
            ".... EPOCH 26 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3672 - accuracy: 0.8685\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4037 - accuracy: 0.8555\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3715 - accuracy: 0.8733\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3738 - accuracy: 0.8687\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3699 - accuracy: 0.8645\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3736 - accuracy: 0.8644\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3745 - accuracy: 0.8601\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3821 - accuracy: 0.8590\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3931 - accuracy: 0.8569\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3701 - accuracy: 0.8580\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3876 - accuracy: 0.8563\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3806 - accuracy: 0.8630\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3603 - accuracy: 0.8647\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3594 - accuracy: 0.8640\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 3s 4ms/step - loss: 0.3834 - accuracy: 0.8626\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3869 - accuracy: 0.8654\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3913 - accuracy: 0.8613\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3732 - accuracy: 0.8656\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3928 - accuracy: 0.8606\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3717 - accuracy: 0.8602\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3884 - accuracy: 0.8623\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3630 - accuracy: 0.8700\n",
            ".... EPOCH 27 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3638 - accuracy: 0.8691\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4006 - accuracy: 0.8557\n",
            "CLEARING BACKEND....\n",
            "... EDGE SERVERS INITIALIZED ...\n",
            "BACKEND CLEARED!\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3591 - accuracy: 0.8707\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3700 - accuracy: 0.8662\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3897 - accuracy: 0.8685\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3686 - accuracy: 0.8632\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3892 - accuracy: 0.8577\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3649 - accuracy: 0.8685\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3800 - accuracy: 0.8631\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3749 - accuracy: 0.8599\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3858 - accuracy: 0.8506\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3738 - accuracy: 0.8643\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3652 - accuracy: 0.8630\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3548 - accuracy: 0.8654\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3801 - accuracy: 0.8551\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3821 - accuracy: 0.8566\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3748 - accuracy: 0.8577\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3730 - accuracy: 0.8636\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3769 - accuracy: 0.8557\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3700 - accuracy: 0.8684\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3681 - accuracy: 0.8730\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3599 - accuracy: 0.8769\n",
            ".... EPOCH 28 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3612 - accuracy: 0.8699\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3988 - accuracy: 0.8570\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3744 - accuracy: 0.8741\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3660 - accuracy: 0.8695\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3570 - accuracy: 0.8698\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3700 - accuracy: 0.8679\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3645 - accuracy: 0.8667\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3610 - accuracy: 0.8726\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3751 - accuracy: 0.8599\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3877 - accuracy: 0.8612\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3793 - accuracy: 0.8568\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3558 - accuracy: 0.8682\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3537 - accuracy: 0.8661\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3608 - accuracy: 0.8624\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3498 - accuracy: 0.8677\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3908 - accuracy: 0.8530\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3782 - accuracy: 0.8636\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3578 - accuracy: 0.8740\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3592 - accuracy: 0.8650\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3554 - accuracy: 0.8699\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3589 - accuracy: 0.8727\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3452 - accuracy: 0.8729\n",
            ".... EPOCH 29 DONE ....\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3566 - accuracy: 0.8711\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3940 - accuracy: 0.8575\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3827 - accuracy: 0.8611\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3482 - accuracy: 0.8823\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3666 - accuracy: 0.8702\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3570 - accuracy: 0.8718\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3756 - accuracy: 0.8628\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3775 - accuracy: 0.8611\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3674 - accuracy: 0.8679\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3594 - accuracy: 0.8689\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3772 - accuracy: 0.8656\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3723 - accuracy: 0.8667\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3436 - accuracy: 0.8733\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3416 - accuracy: 0.8759\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3734 - accuracy: 0.8676\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3672 - accuracy: 0.8704\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3653 - accuracy: 0.8717\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3678 - accuracy: 0.8667\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3601 - accuracy: 0.8696\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3766 - accuracy: 0.8667\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3780 - accuracy: 0.8630\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3450 - accuracy: 0.8826\n",
            ".... EPOCH 30 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3533 - accuracy: 0.8727\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3921 - accuracy: 0.8592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3692 - accuracy: 0.8733\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3575 - accuracy: 0.8770\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3755 - accuracy: 0.8683\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3460 - accuracy: 0.8687\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3709 - accuracy: 0.8645\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3565 - accuracy: 0.8704\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3698 - accuracy: 0.8663\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8760\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3766 - accuracy: 0.8603\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3909 - accuracy: 0.8537\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 3ms/step - loss: 0.3467 - accuracy: 0.8715\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3511 - accuracy: 0.8717\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3765 - accuracy: 0.8606\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3549 - accuracy: 0.8742\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3599 - accuracy: 0.8683\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3712 - accuracy: 0.8672\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8646\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3684 - accuracy: 0.8635\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3656 - accuracy: 0.8664\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3635 - accuracy: 0.8653\n",
            ".... EPOCH 31 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3500 - accuracy: 0.8727\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3885 - accuracy: 0.8614\n",
            "CLEARING BACKEND....\n",
            "... EDGE SERVERS INITIALIZED ...\n",
            "BACKEND CLEARED!\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3574 - accuracy: 0.8739\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3670 - accuracy: 0.8706\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3792 - accuracy: 0.8599\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3431 - accuracy: 0.8727\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3756 - accuracy: 0.8618\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3555 - accuracy: 0.8754\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3656 - accuracy: 0.8677\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3696 - accuracy: 0.8620\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3737 - accuracy: 0.8679\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3904 - accuracy: 0.8633\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3557 - accuracy: 0.8670\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3482 - accuracy: 0.8641\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3616 - accuracy: 0.8664\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3606 - accuracy: 0.8687\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3780 - accuracy: 0.8603\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3560 - accuracy: 0.8719\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3773 - accuracy: 0.8604\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3543 - accuracy: 0.8640\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3502 - accuracy: 0.8722\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3467 - accuracy: 0.8747\n",
            ".... EPOCH 32 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3479 - accuracy: 0.8734\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3876 - accuracy: 0.8615\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3689 - accuracy: 0.8702\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3586 - accuracy: 0.8784\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3712 - accuracy: 0.8690\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3555 - accuracy: 0.8737\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3615 - accuracy: 0.8720\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3571 - accuracy: 0.8649\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3536 - accuracy: 0.8722\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3716 - accuracy: 0.8652\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3687 - accuracy: 0.8658\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3625 - accuracy: 0.8681\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3490 - accuracy: 0.8692\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3487 - accuracy: 0.8755\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3581 - accuracy: 0.8684\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3544 - accuracy: 0.8710\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3468 - accuracy: 0.8783\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3630 - accuracy: 0.8684\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3624 - accuracy: 0.8619\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3728 - accuracy: 0.8628\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3476 - accuracy: 0.8707\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8795\n",
            ".... EPOCH 33 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3446 - accuracy: 0.8739\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3840 - accuracy: 0.8609\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3622 - accuracy: 0.8748\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3579 - accuracy: 0.8720\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3513 - accuracy: 0.8714\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3663 - accuracy: 0.8680\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3486 - accuracy: 0.8769\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3593 - accuracy: 0.8728\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3692 - accuracy: 0.8614\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3578 - accuracy: 0.8659\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3732 - accuracy: 0.8684\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3517 - accuracy: 0.8697\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3696 - accuracy: 0.8681\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3387 - accuracy: 0.8772\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3551 - accuracy: 0.8701\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3540 - accuracy: 0.8686\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3535 - accuracy: 0.8743\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3459 - accuracy: 0.8691\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3407 - accuracy: 0.8705\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3679 - accuracy: 0.8600\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3572 - accuracy: 0.8723\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3319 - accuracy: 0.8789\n",
            ".... EPOCH 34 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3422 - accuracy: 0.8753\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3819 - accuracy: 0.8622\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3570 - accuracy: 0.8784\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3517 - accuracy: 0.8771\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3544 - accuracy: 0.8680\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3509 - accuracy: 0.8656\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3655 - accuracy: 0.8631\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3329 - accuracy: 0.8829\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3732 - accuracy: 0.8637\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3492 - accuracy: 0.8713\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3712 - accuracy: 0.8688\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3471 - accuracy: 0.8747\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3392 - accuracy: 0.8735\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3310 - accuracy: 0.8782\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3385 - accuracy: 0.8745\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3491 - accuracy: 0.8724\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3557 - accuracy: 0.8704\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.8815\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3533 - accuracy: 0.8676\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3518 - accuracy: 0.8682\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3520 - accuracy: 0.8699\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3473 - accuracy: 0.8773\n",
            ".... EPOCH 35 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3397 - accuracy: 0.8768\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3793 - accuracy: 0.8652\n",
            "CLEARING BACKEND....\n",
            "... EDGE SERVERS INITIALIZED ...\n",
            "BACKEND CLEARED!\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3657 - accuracy: 0.8709\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3487 - accuracy: 0.8743\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3481 - accuracy: 0.8729\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3546 - accuracy: 0.8701\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3713 - accuracy: 0.8680\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3424 - accuracy: 0.8760\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3728 - accuracy: 0.8594\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3455 - accuracy: 0.8798\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8781\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3645 - accuracy: 0.8685\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3249 - accuracy: 0.8815\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3356 - accuracy: 0.8815\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3498 - accuracy: 0.8754\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3410 - accuracy: 0.8695\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3584 - accuracy: 0.8700\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3455 - accuracy: 0.8735\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3703 - accuracy: 0.8578\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3461 - accuracy: 0.8699\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3559 - accuracy: 0.8753\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3566 - accuracy: 0.8730\n",
            ".... EPOCH 36 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3379 - accuracy: 0.8767\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3791 - accuracy: 0.8624\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3649 - accuracy: 0.8743\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3523 - accuracy: 0.8715\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3529 - accuracy: 0.8743\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3535 - accuracy: 0.8680\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3429 - accuracy: 0.8778\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3453 - accuracy: 0.8783\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3340 - accuracy: 0.8730\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3364 - accuracy: 0.8775\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3504 - accuracy: 0.8786\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3353 - accuracy: 0.8799\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3422 - accuracy: 0.8732\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3465 - accuracy: 0.8723\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3412 - accuracy: 0.8728\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3424 - accuracy: 0.8750\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3354 - accuracy: 0.8776\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3416 - accuracy: 0.8768\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3538 - accuracy: 0.8738\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3478 - accuracy: 0.8720\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3422 - accuracy: 0.8772\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3292 - accuracy: 0.8833\n",
            ".... EPOCH 37 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3351 - accuracy: 0.8782\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8644\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3419 - accuracy: 0.8807\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3221 - accuracy: 0.8883\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3533 - accuracy: 0.8707\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3481 - accuracy: 0.8726\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3604 - accuracy: 0.8709\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3521 - accuracy: 0.8720\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3318 - accuracy: 0.8798\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3493 - accuracy: 0.8714\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3488 - accuracy: 0.8703\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3505 - accuracy: 0.8762\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3326 - accuracy: 0.8725\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3092 - accuracy: 0.8911\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3397 - accuracy: 0.8705\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3446 - accuracy: 0.8785\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3480 - accuracy: 0.8737\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3482 - accuracy: 0.8726\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3434 - accuracy: 0.8710\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3510 - accuracy: 0.8690\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3202 - accuracy: 0.8802\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3328 - accuracy: 0.8837\n",
            ".... EPOCH 38 DONE ....\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3341 - accuracy: 0.8779\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8638\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3366 - accuracy: 0.8779\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3309 - accuracy: 0.8826\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3496 - accuracy: 0.8719\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3449 - accuracy: 0.8762\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3532 - accuracy: 0.8744\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3427 - accuracy: 0.8755\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3516 - accuracy: 0.8667\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8785\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3595 - accuracy: 0.8641\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3380 - accuracy: 0.8796\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8836\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3264 - accuracy: 0.8791\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3456 - accuracy: 0.8717\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3349 - accuracy: 0.8759\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3419 - accuracy: 0.8775\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3496 - accuracy: 0.8719\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.8686\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3470 - accuracy: 0.8743\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3437 - accuracy: 0.8757\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3209 - accuracy: 0.8832\n",
            ".... EPOCH 39 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3301 - accuracy: 0.8790\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3718 - accuracy: 0.8659\n",
            "CLEARING BACKEND....\n",
            "... EDGE SERVERS INITIALIZED ...\n",
            "BACKEND CLEARED!\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3372 - accuracy: 0.8793\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3326 - accuracy: 0.8821\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3542 - accuracy: 0.8719\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3453 - accuracy: 0.8734\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3644 - accuracy: 0.8748\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3394 - accuracy: 0.8768\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3647 - accuracy: 0.8675\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3322 - accuracy: 0.8739\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3683 - accuracy: 0.8675\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3450 - accuracy: 0.8744\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3258 - accuracy: 0.8768\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3304 - accuracy: 0.8772\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3561 - accuracy: 0.8676\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3292 - accuracy: 0.8796\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3350 - accuracy: 0.8797\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3523 - accuracy: 0.8764\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3502 - accuracy: 0.8707\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3392 - accuracy: 0.8770\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3298 - accuracy: 0.8782\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3242 - accuracy: 0.8811\n",
            ".... EPOCH 40 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3275 - accuracy: 0.8810\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3697 - accuracy: 0.8667\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3443 - accuracy: 0.8788\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3244 - accuracy: 0.8858\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.8728\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3296 - accuracy: 0.8815\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3515 - accuracy: 0.8745\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3279 - accuracy: 0.8805\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3473 - accuracy: 0.8650\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3238 - accuracy: 0.8818\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3631 - accuracy: 0.8685\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3422 - accuracy: 0.8768\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3273 - accuracy: 0.8756\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3298 - accuracy: 0.8821\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3435 - accuracy: 0.8774\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3192 - accuracy: 0.8805\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3450 - accuracy: 0.8748\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3337 - accuracy: 0.8795\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3368 - accuracy: 0.8740\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3424 - accuracy: 0.8704\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3280 - accuracy: 0.8837\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3227 - accuracy: 0.8843\n",
            ".... EPOCH 41 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3259 - accuracy: 0.8820\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3680 - accuracy: 0.8665\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3555 - accuracy: 0.8672\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3246 - accuracy: 0.8839\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3388 - accuracy: 0.8717\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3522 - accuracy: 0.8683\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3411 - accuracy: 0.8763\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3396 - accuracy: 0.8789\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3507 - accuracy: 0.8730\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3249 - accuracy: 0.8785\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3328 - accuracy: 0.8756\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3423 - accuracy: 0.8728\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3170 - accuracy: 0.8800\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3266 - accuracy: 0.8841\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3323 - accuracy: 0.8755\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3166 - accuracy: 0.8863\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3388 - accuracy: 0.8711\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3329 - accuracy: 0.8763\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3497 - accuracy: 0.8689\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3330 - accuracy: 0.8801\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3219 - accuracy: 0.8893\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3238 - accuracy: 0.8822\n",
            ".... EPOCH 42 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3243 - accuracy: 0.8808\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3672 - accuracy: 0.8679\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3430 - accuracy: 0.8763\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3261 - accuracy: 0.8883\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3436 - accuracy: 0.8766\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3263 - accuracy: 0.8834\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3435 - accuracy: 0.8727\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3335 - accuracy: 0.8774\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3410 - accuracy: 0.8698\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3266 - accuracy: 0.8787\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3260 - accuracy: 0.8812\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8815\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3206 - accuracy: 0.8858\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.8787\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3098 - accuracy: 0.8873\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3327 - accuracy: 0.8743\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3317 - accuracy: 0.8729\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3303 - accuracy: 0.8779\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3270 - accuracy: 0.8803\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3318 - accuracy: 0.8726\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3139 - accuracy: 0.8866\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3144 - accuracy: 0.8899\n",
            ".... EPOCH 43 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3219 - accuracy: 0.8825\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3644 - accuracy: 0.8691\n",
            "CLEARING BACKEND....\n",
            "... EDGE SERVERS INITIALIZED ...\n",
            "BACKEND CLEARED!\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3206 - accuracy: 0.8863\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3280 - accuracy: 0.8826\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3368 - accuracy: 0.8762\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3471 - accuracy: 0.8735\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3344 - accuracy: 0.8788\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3323 - accuracy: 0.8818\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3340 - accuracy: 0.8751\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3223 - accuracy: 0.8827\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3362 - accuracy: 0.8774\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3505 - accuracy: 0.8731\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3184 - accuracy: 0.8855\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3176 - accuracy: 0.8878\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3327 - accuracy: 0.8768\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3376 - accuracy: 0.8779\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3241 - accuracy: 0.8821\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3326 - accuracy: 0.8805\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3325 - accuracy: 0.8734\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3424 - accuracy: 0.8744\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3286 - accuracy: 0.8850\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3124 - accuracy: 0.8891\n",
            ".... EPOCH 44 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3203 - accuracy: 0.8829\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3627 - accuracy: 0.8684\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3362 - accuracy: 0.8794\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3248 - accuracy: 0.8869\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3388 - accuracy: 0.8712\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3287 - accuracy: 0.8822\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3328 - accuracy: 0.8850\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3251 - accuracy: 0.8866\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3439 - accuracy: 0.8703\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3269 - accuracy: 0.8807\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3443 - accuracy: 0.8792\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3427 - accuracy: 0.8812\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3186 - accuracy: 0.8870\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3072 - accuracy: 0.8871\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3513 - accuracy: 0.8731\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3363 - accuracy: 0.8798\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3244 - accuracy: 0.8804\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3308 - accuracy: 0.8804\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3109 - accuracy: 0.8850\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3333 - accuracy: 0.8722\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3222 - accuracy: 0.8892\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3120 - accuracy: 0.8907\n",
            ".... EPOCH 45 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3179 - accuracy: 0.8836\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3618 - accuracy: 0.8692\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3297 - accuracy: 0.8821\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3261 - accuracy: 0.8835\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3448 - accuracy: 0.8706\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3064 - accuracy: 0.8917\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3482 - accuracy: 0.8711\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3369 - accuracy: 0.8765\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3253 - accuracy: 0.8832\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3146 - accuracy: 0.8821\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3416 - accuracy: 0.8783\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3364 - accuracy: 0.8771\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3104 - accuracy: 0.8804\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3146 - accuracy: 0.8850\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3416 - accuracy: 0.8692\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3207 - accuracy: 0.8860\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3224 - accuracy: 0.8805\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3372 - accuracy: 0.8783\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3230 - accuracy: 0.8787\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3310 - accuracy: 0.8756\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3350 - accuracy: 0.8801\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3208 - accuracy: 0.8811\n",
            ".... EPOCH 46 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3167 - accuracy: 0.8844\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3606 - accuracy: 0.8699\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3277 - accuracy: 0.8770\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3107 - accuracy: 0.8905\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3377 - accuracy: 0.8771\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3280 - accuracy: 0.8866\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3355 - accuracy: 0.8820\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3257 - accuracy: 0.8783\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3193 - accuracy: 0.8777\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3267 - accuracy: 0.8837\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3239 - accuracy: 0.8849\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3288 - accuracy: 0.8794\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3141 - accuracy: 0.8846\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3040 - accuracy: 0.8891\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3156 - accuracy: 0.8814\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3151 - accuracy: 0.8857\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3400 - accuracy: 0.8794\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3312 - accuracy: 0.8798\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3269 - accuracy: 0.8793\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3321 - accuracy: 0.8802\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3220 - accuracy: 0.8840\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3186 - accuracy: 0.8913\n",
            ".... EPOCH 47 DONE ....\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3149 - accuracy: 0.8854\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3586 - accuracy: 0.8713\n",
            "CLEARING BACKEND....\n",
            "... EDGE SERVERS INITIALIZED ...\n",
            "BACKEND CLEARED!\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3332 - accuracy: 0.8886\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3243 - accuracy: 0.8920\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3370 - accuracy: 0.8763\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3411 - accuracy: 0.8695\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3303 - accuracy: 0.8794\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3128 - accuracy: 0.8871\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3366 - accuracy: 0.8787\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3418 - accuracy: 0.8744\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3386 - accuracy: 0.8761\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 0.3476 - accuracy: 0.8784\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3068 - accuracy: 0.8852\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3042 - accuracy: 0.8947\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3291 - accuracy: 0.8770\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3090 - accuracy: 0.8864\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3169 - accuracy: 0.8837\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3324 - accuracy: 0.8794\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3165 - accuracy: 0.8895\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3191 - accuracy: 0.8815\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3202 - accuracy: 0.8901\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3152 - accuracy: 0.8892\n",
            ".... EPOCH 48 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3133 - accuracy: 0.8852\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3578 - accuracy: 0.8694\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3191 - accuracy: 0.8934\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3104 - accuracy: 0.8953\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3263 - accuracy: 0.8756\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3209 - accuracy: 0.8810\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3224 - accuracy: 0.8799\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3139 - accuracy: 0.8876\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3130 - accuracy: 0.8865\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.8739\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3273 - accuracy: 0.8841\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3337 - accuracy: 0.8806\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3000 - accuracy: 0.8930\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3046 - accuracy: 0.8867\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3146 - accuracy: 0.8869\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3175 - accuracy: 0.8834\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3269 - accuracy: 0.8754\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3334 - accuracy: 0.8797\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3250 - accuracy: 0.8831\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3291 - accuracy: 0.8780\n",
            "Epoch 1/2\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.3242 - accuracy: 0.8856\n",
            "Epoch 2/2\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3088 - accuracy: 0.8918\n",
            ".... EPOCH 49 DONE ....\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3112 - accuracy: 0.8871\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3559 - accuracy: 0.8705\n",
            "TEST SET EVALUATION\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3566 - accuracy: 0.8729\n",
            "[0.35591381788253784, 0.8705000281333923]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACCCAYAAABW3zPjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAX9UlEQVR4nO3de3RU1fXA8e8mkAckQkKCPAIEFBEMECSGl9WgxVJRaRUtCK6y7KrYqiiVotj606IU6MtHq0vBUl1VsaxaLCr1ASJYaZVQEOThowRKQAPhGRQJCef3x55hhhjCQGa4kzv7s9ZdmfuYO/vKuOfcc849R5xzGGOMafyaeB2AMcaY6LCEbowxPmEJ3RhjfMISujHG+IQldGOM8QlL6MYY4xNNvfrg7Oxsl5eX59XHG2NMo7Ry5coK51xOXfs8S+h5eXmUlJR49fHGGNMoiciW4+2zKhdjjPEJS+jGGOMTjS+hr1sH48fDzp1eR2KMMXHFszr0U7Z/P8yaBZddBtdc43U0xvjG4cOHKSsr46uvvvI6FAOkpqaSm5tLs2bNIn5P40vohYXQvDksXWoJ3ZgoKisrIyMjg7y8PETE63ASmnOOXbt2UVZWRpcuXSJ+X+OrcmnWDAYPhrff9joSY3zlq6++onXr1pbM44CI0Lp165O+W2p8CR2guBjWroWKCq8jMcZXLJnHj1P5t2icCf3iiyEvD7YctzumMaaR2bVrFwUFBRQUFNC2bVs6dOhwdL2qqqre95aUlDBhwoQTfsagQYOiEuvbb7/NFVdcEZVzRVNEdegiMgx4BEgCnnLOzai1vxPwDNAqcMzdzrmFUY41ZNAgKC2N2emNMadf69atWb16NQD3338/6enpTJo06ej+6upqmjatO2UVFhZSWFh4ws9Yvnx5dIKNUycsoYtIEvAY8G2gJzBaRHrWOuznwDznXF9gFPB4tAOtFZT+tdmWjPG1cePGcfPNN9O/f38mT57M+++/z8CBA+nbty+DBg3io48+Ao4tMd9///3ceOONFBcX07VrVx599NGj50tPTz96fHFxMSNHjuTcc89lzJgxBGdvW7hwIeeeey79+vVjwoQJJ1USnzt3Lr169SI/P5+77roLgJqaGsaNG0d+fj69evXioYceAuDRRx+lZ8+e9O7dm1GjRjX8PxaRldCLgE+dc5sAROQFYASwPuwYB5wReN0S2B6V6Orzt7/BbbdpXXpWVsw/zpiEU1z89W3XXQc//jF8+SVcfvnX948bp0tFBYwceey+U+zIUFZWxvLly0lKSmL//v288847NG3alEWLFnHPPffw4osvfu09GzduZMmSJVRWVtK9e3d+9KMffa3736pVq1i3bh3t27dn8ODBvPvuuxQWFjJ+/HiWLVtGly5dGD16dMRxbt++nbvuuouVK1eSmZnJZZddxksvvUTHjh3Ztm0bH374IQB79+4FYMaMGZSWlpKSknJ0W0NFUofeAdgatl4W2BbufmCsiJQBC4HbohJdfXJyYPt2eOedmH+UMcY71157LUlJSQDs27ePa6+9lvz8fCZOnMi6devqfM/w4cNJSUkhOzubNm3aUF5e/rVjioqKyM3NpUmTJhQUFLB582Y2btxI165dj3YVPJmEvmLFCoqLi8nJyaFp06aMGTOGZcuW0bVrVzZt2sRtt93Ga6+9xhlnaNm3d+/ejBkzhmefffa4VUknK1r90EcDTzvnfisiA4E/i0i+c+5I+EEichNwE0CnTp0a9olFRZCaqr/6I0Y07FzGmK+rr0TdvHn9+7Ozo9a1uEWLFkdf33vvvQwZMoT58+ezefNmiuu6iwBSUlKOvk5KSqK6uvqUjomGzMxMPvjgA15//XWeeOIJ5s2bx5w5c3j11VdZtmwZL7/8MtOmTWPt2rUNTuyRlNC3AR3D1nMD28L9AJgH4Jz7F5AKZNc+kXNulnOu0DlXmJNT5+iPkUtJgYED9QEjY0xC2LdvHx06aAXB008/HfXzd+/enU2bNrF582YA/vKXv0T83qKiIpYuXUpFRQU1NTXMnTuXiy++mIqKCo4cOcI111zDgw8+yH/+8x+OHDnC1q1bGTJkCDNnzmTfvn0cOHCgwfFHktBXAN1EpIuIJKONngtqHfM/4FIAEemBJvTYD7ZSXAyrV8OePTH/KGOM9yZPnsyUKVPo27dvTErUaWlpPP744wwbNox+/fqRkZFBy5Yt6zx28eLF5ObmHl02b97MjBkzGDJkCH369KFfv36MGDGCbdu2UVxcTEFBAWPHjmX69OnU1NQwduxYevXqRd++fZkwYQKtWrVqcPziIugpIiKXAw+jXRLnOOemichUoMQ5tyDQ62U2kI42kE52zr1R3zkLCwtdg8dDX7kSnnkGpkyBdu0adi5jEtyGDRvo0aOH12F47sCBA6Snp+Oc45ZbbqFbt25MnDjRk1jq+jcRkZXOuTr7aEZUYRPoU76w1rb/C3u9Hhh80tE2VL9+uhhjTJTMnj2bZ555hqqqKvr27cv48eO9DilijW9wrtqqq2HjRsjP9zoSY4wPTJw40bMSeUM1zkf/w/3yl9CnD0SpH6cxxjRWjT+hf+MbcOQI/POfXkdiTKMXSZuaOT1O5d+i8Sf0AQMgOdmG0zWmgVJTU9m1a5cl9TgQHA89NTX1pN7X+OvQ09I0qVt/dGMaJDc3l7KyMnba9I5xIThj0clo/AkdtD/6gw/Cvn1wnD6jxpj6NWvW7KRmxzHxxx8J/YYbtC49Lc3rSIwxxjP+SOhnn62LMcYksMbfKBpUUgKPx3YYdmOMiWf+Seh//ztMmACVlV5HYowxnvBPQr/kEqipgXnzvI7EGGM84Z+EXlys3Rd//nMrpRtjEpJ/EroIPPwwfP45TJ/udTTGGHPa+SehA/TvDzfdBIGJYI0xJpH4o9tiuCef9DoCY4zxhL9K6EHOwYIF8O9/ex2JMcacNv4roQMcOgS33qoT1a5YAYEZw40xxs/8WUJPTYWZM2HVKp2izhhjEoA/EzrAqFHajfGee6wbozEmIfg3oYvAI49AebnOamSMMT7n34QOUFQEd94J553ndSTGGBNz/mwUDfeb34Re19RYA6kxxrf8XUIPN2sWDBkCX37pdSTGGBMTiZPQs7Lg3Xdh5EioqvI6GmOMibqIErqIDBORj0TkUxG5+zjHXCci60VknYg8H90wo2DkSHjiCfjHP2DcODhyxOuIjDEmqk5Yhy4iScBjwFCgDFghIgucc+vDjukGTAEGO+f2iEibWAXcID/8IezaBVOmaIn997/X3jDGGOMDkTSKFgGfOuc2AYjIC8AIYH3YMT8EHnPO7QFwzu2IdqBRc9ddsHs35ORYMjfG+EokCb0DsDVsvQzoX+uYcwBE5F0gCbjfOfdaVCKMNhH41a9C66WlkJdnyd0Y0+hFq1G0KdANKAZGA7NFpFXtg0TkJhEpEZGSnTt3RumjG6C0FPr00SF3raHUGNPIRZLQtwEdw9ZzA9vClQELnHOHnXOlwMdogj+Gc26Wc67QOVeYk5NzqjFHT+fOOg/pU0/B0KFQUeF1RMYYc8oiSegrgG4i0kVEkoFRwIJax7yEls4RkWy0CmZTFOOMjSZN4MEH4bnn4L33dIKMdeu8jsoYY07JCRO6c64auBV4HdgAzHPOrRORqSJyVeCw14FdIrIeWAL81Dm3K1ZBR93118PSpfrQ0RNPeB2NMcacEnHOefLBhYWFrqSkxJPPPq7t23UM9eRk2LIFcnNtqABjTFwRkZXOucK69iXOk6KRaN9ek/mhQ3DppTBwIKxe7XVUxhgTEUvodUlOhmnTtJReWAiTJ8MXX3gdlTHG1MsSel1E4Hvfg40b4cYb4de/hvx8TfDGGBOnLKHXJzNTR2lcuhQuugg6BnpvHjzobVzGGFMHS+iRuOginZu0SRMdCyYvDyZN0tfGGBMnLKGfrJoaGD4cfvc7OOssmDHDxlg3xsQFS+gnq00bmDMH1qyBb3xDR2485xzYs8fryIwxCc4S+qnKz4eXX9b69Rtv1Pp2gBdegM8+8zY2Y0xCsoTeUBddBFOn6uudO+GGG6BTJxg9GpYvB48e3DLGJB5L6NGUkwMbNsCtt+rMSIMHQ79+sGqV15EZYxKAJfRoO/tseOghKCvTcWGcgzPP1H3vv6+DgFmp3RgTA5bQYyU9HcaP19J5+/a6bepUGDAAeveGRx+1bo/GmKiyhH46Pf88PPkkpKXB7bdD27Zwxx1eR2WM8QlL6KfTGWfo7Ejvv6+Dfk2aBL166b4DB+DKK3WyDSu5G2NOQSRzippY6NNHl6DSUm1QfeUVuPlmuPBCuOoqGDtW+74bY8wJWAk9XvTqBZ98AitXwt13w+7dcOed8Pnnun/dOi3Z19R4G6cxJm5ZQo8nInD++Tot3po1WmoPVsn89rc6RV52Nlx9NTz+OHz0kfWYMcYcZVUu8SwvL/T6N7/RiawXL4ZFi2D+fOjSBTYFpm596y0dDfLss/WHwRiTcCyhNxZZWfr06ejRWirftEn7uoOujx4NO3Zoz5kLL9RxZoYOhR49vI3bGHPaWJVLYySiIz1efHFo25Il+iDTpZdqXfvtt+tY7gCHD2u/9zVr4MgRb2I2xsScTRLtV//7nyb+jh21obUwMKds69ZQXKw/BldfDR06eBqmMebk1DdJtFW5+FWnTqHX/frp9HlLloSWF1/UESM7dNAS/cKFOvZM//7aX94Y0+hYQk8UnTrB97+vC2gJPjjGzHvvwQMPhKpjunbV4Qn+9Cdo1QoqK6FFC52xyRgTtyyhJ6rwEvxtt2mi//e/tbS+di18/DFkZOj+SZPguec0yRcU6NK3L1xwgTexG2PqFFEduogMAx4BkoCnnHMzjnPcNcBfgQucc/VWkFsdeiPyyivwxhvwwQc6ZMH+/VqK/+9/df8vf6kTZ/fooUv37tC8ubcxG+NTDapDF5Ek4DFgKFAGrBCRBc659bWOywBuB95reMgmrlxxhS6gXSQ3b4by8tD+RYt05qZglY0IXHedzt4EWj/fubNO1des2WkN3ZhEEkmVSxHwqXNuE4CIvACMANbXOu4BYCbw06hGaOKLiD7Q1KVLaNtbb8GhQzp0wYYNsHFjqPdMdbX2pjl0CJKTtQTfsydcey1897v6A7Fvn9bVG2MaJJKE3gHYGrZeBvQPP0BEzgc6OudeFRFL6IkoJUV7zeTnH7u9SRNYsUL7wK9dq3//9a/QkAbl5dCunXan7NYttIwYoXX2xpiINbhRVESaAL8DxkVw7E3ATQCdwhvljH81aaLJO5jAg4JtN8nJ8OtfayPsJ59oaf/Pf9ZG2969oaQELr9cH6Q66yytuz/rLLjsMv0hMMYcFUlC3wZ0DFvPDWwLygDygbdFxxBpCywQkatqN4w652YBs0AbRRsQt2nsguPNZGVpL5pwX34Zet2ihZbWN22Cd9+FuXO1rn7RIk3of/2rjjGfna1zumZn6zJlio5rs3+/nsf61psEEElCXwF0E5EuaCIfBVwf3Omc2wdkB9dF5G1g0ol6uRhzXOE9ZHr0gNmzQ+tVVdqHPjitX+fOcP31UFGhy5YtWqr/2c90/x//CD/5iY5xc845muQ7d4aJE7Vb5oEDWl1kjbXGB06Y0J1z1SJyK/A62m1xjnNunYhMBUqccwtiHaQxRyUna1IOuuCC+vvDDxkCM2fqUMMff6w9bsrLYfJk3X/vvTrOTbt2oRJ+mzbw7LN6F7F0qY5N37Ej5ObqPnvAysSpiOrQnXMLgYW1tv3fcY4tbnhYxkRJ8EGocIcOaakcYPhwndB761ad+q+iAvbsCVUJ/eEPWq0TlJys53sv0Dt39mz9gTjzzNDSvr3+ABhzmtngXMbUZ9curcYpK9OkX1YGSUk6CQno6JZvvXXsey64QJ+4De7fuhUyM7V036kTDBgAN9wQOn9mppX6TcRscC5jTlXr1rqcf37d+xcvhq++0rHoy8t1SU4O7R88WHvv7N6tif2f/9RpBYMJvWdPvSNo0ya0XHkl3HKL7n/uOW04PvPM0P7w8xsTxhK6MQ2Vmqol77q64k6d+vVthw/rX+fgvvu0kXfHjtCyc6fur6rSScJru/tumD5dB00bOlR7ArVooY3JWVlwzTV6Z1BVFXrIKyvLZrJKAJbQjTndgj1qRODHPz7+cU2b6ng5wZJ/cBkwQPcfPgwtW8IXX+gdwBdfaBXOOedoQi8thT59Qp/ZqpUu06dr0i8t1XF4srK02icrS5dBg7Qd4OBBPV9amv5opaVZ1VCcs4RuTLxq0kQfpOrate79WVnw+utf3x5sF2vbFubNg+3btZpn3z7Yu1d78oDeCbzyiv4YVFWF3j9/PnznOzpu/vDhx547OVl7Cl16KSxfrpOVBxuDMzN1/5VXamxbtugdQvPm2ouoXTu9kzAxYwndGL8JVq20bKlj5hxPURF89pn+ABw8qIl99+5Q1VF+vk5jePDgsUuw22h5uT7sVV6u24PWrNGE/vLLOjRzuJYtYdUqHQvotdd0yczUpVUr/futb+kPw969UFOjzwtYu0FErJeLMabhDhzQBHz4sFbXpKToXUFpqe77/HO9U9i2Tat8WrSAadP0GYHKymPP9eWXWr1zxx3wyCO6LSVFn/bNyIBPP9UfrZkz9Ynh5s2162lWlt6VBB8q++ADPVdGhi7B9zdt3OVY6+VijImt9HRdwrVtq8vx/OxnulRXa3XQnj26pKXp/pEjtSRfWRlaDh8O3YFUV+uPxc6dum/PHk3uwYR+7716lxAufBz/G27Qu4lg7Onp2uvogQd0/5NP6h1LWlroR6NTJ7jwQt1fVqY/NBkZ+jcOGp2thG6M8Y8jR0INt+vXaw+iykod06eyUpPz+PG6/777tBR/4EBo6d5d59sFbVBes+bY83/zm/Dmm/q6a1e9AwH9zBYtdKjop5/WbVdeqT9AwTuDM87QBuf6qsEiYCV0Y0xiCO+F07OnLsfzi1/Uf67Vq7Wx+OBB7UH0xRf6UFnQzJnaflBZGdp/3nnHnmPPHm0cDt5hHDzY4IReH0voxhhTFxGtSklJqXsClhMl5trVPaeBdSo1xhifsIRujDE+YQndGGN8wrNeLiKyE9hygsOygYrTEE68setOLIl63ZC4196Q6+7snMupa4dnCT0SIlJyvO45fmbXnVgS9bohca89VtdtVS7GGOMTltCNMcYn4j2hz/I6AI/YdSeWRL1uSNxrj8l1x3UdujHGmMjFewndGGNMhOI2oYvIMBH5SEQ+FZG7vY4nVkRkjojsEJEPw7ZlicibIvJJ4G+mlzHGgoh0FJElIrJeRNaJyO2B7b6+dhFJFZH3ReSDwHX/IrC9i4i8F/i+/0VEfDkAuIgkicgqEXklsO776xaRzSKyVkRWi0hJYFtMvudxmdBFJAl4DPg20BMYLSL1jLLTqD0NDKu17W5gsXOuG7A4sO431cCdzrmewADglsC/sd+v/RBwiXOuD1AADBORAcBM4CHn3NnAHuAHHsYYS7cDG8LWE+W6hzjnCsK6Ksbkex6XCR0oAj51zm1yzlUBLwAjPI4pJpxzy4DdtTaPAJ4JvH4G+M5pDeo0cM595pz7T+B1Jfo/eQd8fu1OHQisNgssDrgE+Gtgu++uG0BEcoHhwFOBdSEBrvs4YvI9j9eE3gHYGrZeFtiWKM50zn0WeP05cKaXwcSaiOQBfYH3SIBrD1Q7rAZ2AG8C/wX2OueqA4f49fv+MDAZOBJYb01iXLcD3hCRlSJyU2BbTL7nNnxunHPOORHxbVckEUkHXgTucM7tl7BZX/x67c65GqBARFoB84FzPQ4p5kTkCmCHc26liBR7Hc9pdqFzbpuItAHeFJGN4Tuj+T2P1xL6NqBj2HpuYFuiKBeRdgCBvzs8jicmRKQZmsyfc879LbA5Ia4dwDm3F1gCDARaiUiwgOXH7/tg4CoR2YxWoV4CPIL/rxvn3LbA3x3oD3gRMfqex2tCXwF0C7SAJwOjgAUex3Q6LQC+H3j9feDvHsYSE4H60z8CG5xzvwvb5etrF5GcQMkcEUkDhqLtB0uAkYHDfHfdzrkpzrlc51we+v/zW865Mfj8ukWkhYhkBF8DlwEfEqPvedw+WCQil6N1bknAHOfcNI9DigkRmQsUo6OvlQP3AS8B84BO6IiU1znnajecNmoiciHwDrCWUJ3qPWg9um+vXUR6o41gSWiBap5zbqqIdEVLrlnAKmCsc+6Qd5HGTqDKZZJz7gq/X3fg+uYHVpsCzzvnpolIa2LwPY/bhG6MMebkxGuVizHGmJNkCd0YY3zCEroxxviEJXRjjPEJS+jGGOMTltCNMcYnLKEbY4xPWEI3xhif+H+iysJX7QCxTAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAEkCAYAAACWg72EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3gV1dn+8e9DCASVMyhIwICigAgoAapIFY9osWClFkpFKoVaxFqqVexbD9Xa1rdaWy3aalU8AQL+QOor4AGs1lIlKIKcFBEkgCWACHKGPL8/1sRsQ4Ag2Zm9k/tzXXNlz5rZw7PdbbhZM2stc3dEREREJPVVi7sAERERESkbBTcRERGRNKHgJiIiIpImFNxERERE0oSCm4iIiEiaUHATERERSRPV4y6gIjRq1MhzcnLiLkNERETkoObOnbve3RuXdqxKBLecnBzy8vLiLkNERETkoMxs5f6O6VapiIiISJpQcBMRERFJEwpuIiIiImmiSjzjVprdu3eTn5/Pjh074i4lbWVlZZGdnU1mZmbcpYiIiFQJVTa45efnU7t2bXJycjCzuMtJO+7Ohg0byM/Pp2XLlnGXIyIiUiVU2VulO3bsoGHDhgptX5OZ0bBhQ/VYioiIVKAqG9wAhbbDpP9+IiIiFatKB7dUMGXKFMyMJUuWxF2KiIiIpDgFt5iNGzeOM888k3HjxiXtz9i7d2/Sri0iIlIZFRYWv77rLvjud2Hy5PjqKaLgFqMvvviCf/3rXzz66KOMHz8eCCHrhhtuoH379nTo0IEHHngAgDlz5nDGGWfQsWNHunbtypYtWxgzZgwjRoz48nq9e/fmtddeA+Coo47i+uuvp2PHjsyePZs77riDLl260L59e4YNG4a7A7Bs2TLOO+88OnbsyGmnncZHH33EoEGDmDJlypfXHThwIM8//3wF/VcRERFJHnfYtQu++KK4bd48ePxxuPFG6N0bjj8ezj+/+PjEieGcjRsrvt6Squyo0pLOPnvftssvh+HDYds2uPjifY8PHhy29euhX7+vHovy0wE9//zz9OrVixNPPJGGDRsyd+5c3n77bVasWMG8efOoXr06GzduZNeuXXzve9/j2WefpUuXLmzevJlatWod8Npbt26lW7du3HvvvQC0a9eOW2+9FYArrriCF154gUsuuYSBAwcyatQoLr30Unbs2EFhYSFDhgzhvvvuo2/fvnz++ef8+9//5oknnjj4BxIREYnB+vWwdCksX168rVsH06aF48OHw4QJsH077NgRetOaNoU1a8Lxm2+G6dOhZk048UTIzYVvfKP4+nPnQkZGxX+u0ii4xWjcuHFcd911APTv359x48bx8ccfc/XVV1O9evhqGjRowIIFC2jatCldunQBoE6dOge9dkZGBpdddtmX+7NmzeJ///d/2bZtGxs3buTkk0/m7LPPZvXq1Vx66aVAmJcN4KyzzmL48OEUFBTw3HPPcdlll31Zj4iISDLt3g1btoTt2GMhMxM++gjeey+0ffYZfPxxCGeTJoWwdeedcP/94f1mkJ0dAliRzp1De1YW1KoVtnr1io/fcw888AC0bFl6QEuV0AYKbl86UA/ZEUcc+HijRmXrYUu0ceNGZs6cyYIFCzAz9u7di5l9Gc7Konr16hQm3IRPnJojKyuLjOh/aTt27GD48OHk5eXRvHlzbr/99oNO4zFo0CCefvppxo8fz+OPP35oH05ERGQ/tm2DDz6AJUvC7ciGDWHMGPjFL0Iw27mz+NwlS+Ckk2DKFLjhhuL2o44KtzM3bgw9Z1ddBRddBK1awXHHhTCXaMiQsO3PySeX60dMKgW3mEyaNIkrrriCv/3tb1+2nXXWWXTs2JG//e1v9OzZ88tbpSeddBJr165lzpw5dOnShS1btlCrVi1ycnJ48MEHKSwsZPXq1bz99tul/llFIa1Ro0Z88cUXTJo0iX79+lG7dm2ys7OZMmUKffv2ZefOnezdu5cjjjiCwYMH07VrV5o0aUK7du0q5L+JiIiktl27YNGi0AMG0KEDtG4dnhebNQuqVQs9W2bh9cknh96vd98NtyOXLIGVK4uvN306XHhhOK9fP6hTB2rXDsGsdm04+uhw3sCBcN55oa1uXWjQIPwZRTp2DFtVoOAWk3HjxnHTTTd9pe2yyy5j8eLFtGjRgg4dOpCZmcnQoUMZMWIEzz77LNdeey3bt2+nVq1avPLKK3Tv3p2WLVvSrl072rZty2mnnVbqn1WvXj2GDh1K+/btadKkyVd69Z566il+/OMfc+utt5KZmcnEiRNp1aoVxxxzDG3btqVv375J/e8gIiLJ4Q5bt4YQBCF0ZWZ+NfAcyObN4ZmwY46B//4XevWChQvDrcwif/wjjBwJq1bBt7+97zUeeQR+9KPw5xYUQPfuoeerbVto0yaEPoAuXcK2P02ahE3AikYXVma5ubmel5f3lbbFixfTtm3bmCpKfdu2beOUU07hnXfeoW7duvs9T/8dRUQq3s6dsHhx6Ok688zQds898OabsHZteOj+009Dj1jRX3/dusH8+eHxnkaNoHHj8AD+HXeE488+C8uWhd6xefNCr9rVV8NDD8HevdCnD7RvD506hduX1auHMNW4cQh4CxeGsFhYWPzz+OND8JNDY2Zz3T23tGPqcZN9vPLKKwwZMoSRI0ceMLSJiEjFWbwYXngBXn0VXn+9uDfs00/D8fffD8GradMQrIp+FhkyBD78MIzALNqK3gvhGbL8fDjhBDj1VPjhD6Fnz3AsIyP82ftTq1YYiSnJp+Am+zjvvPNYmfgQgoiIVCj3MGrylVfCtFM1a4Z5xv7wh3Cb8Uc/Cj1tLVoUv2fMmANfc9iwAx/PywsBrAwTF0iMFNxERERi5B6eO1u7NvRqvfVWCGxF/35u1w569ICf/Sxsxx6bnDp0SzM9JDW4mVkv4M9ABvB3d/99ieMtgCeAetE5o9z9RTMbCPwi4dQOwGnuPs/MXgOaAtujYxe4+7qvU5+7a6H0w1AVno8UESlpx47w/NcHH4RbjaedFp4f27kzzCtWvXrYMjLCzzZtwu3HgoLwvFh+fniYv2gbPRp+8IPQwzZsWJhfrGfPMIv/uecWz0eWrMAm6SVpwc3MMoDRwPlAPjDHzKa6+6KE034FTHD3h8ysHfAikOPuzwDPRNc5BZji7vMS3jfQ3b862uAQZWVlsWHDBho2bKjw9jW4Oxs2bPhy0l4Rkcpkzx5YsSKEs7p1w2jInTvDM2OffBJ6yYrcfHMIblu2hABW0m9/G87Zvh1uuy30bDVvHkZUnnNOCHUQJoldsSJMn5FKE75Kaklmj1tXYJm7Lwcws/FAHyAxuDlQdDe9LrCmlOsMAMaXd3HZ2dnk5+dTUFBQ3peuMrKyssjOzo67DBGRrygshNWrwxJIS5eGEHT11eHYxReHecjci8NX9+4wblzx6xUrwnJJe/aEtu98J7TXrBkmeW3SJISuE08MvWBF023Urx/+vL17w3v37Amvi3rKsrNDb13JyWGLZGWFyWNFDiSZwa0ZsCphPx/oVuKc24GXzOxa4EjgvFKu8z1C4Ev0uJntBZ4DfuOl3LMzs2HAMIAWiU9vRjIzM2nZsmWZPoiIiKQW9zBrftGalN/6Vmj/0Y9CCNu2rfjcU04pDm6dOxdP6lo0UWzijEbf/GbYP/ro4nCWODLzoYf2X1NGxleXWSqpWrX9hzaRsop7cMIAYIy732tmpwNPmVl7dy8EMLNuwDZ3fz/hPQPdfbWZ1SYEtyuAJ0te2N0fBh6GMI9bsj+IiIiUr127wgP6H38clkYyC+tJPvZYCGybN4fzsrLCRLPVqoXZ82vXDmGraGvatPiad9554D/zd79L3ucRKQ/JDG6rgeYJ+9lRW6IhQC8Ad59tZllAI6BosEF/YFziG9x9dfRzi5mNJdyS3Se4iYhIanOHDRtCCDvllDAVxeTJYbHw5cvDQ/xFyzGvWxcmeq1eHZo1C1NhtGoVtuOPL77mtdfG81lEKkoyg9scoLWZtSQEtv7A90uc8wlwLjDGzNoCWUABgJlVAy4HehSdbGbVgXruvt7MMoHewCtJ/AwiInIItm8PIyU//zz0iG3eHF6fd154xmv27DAX2fLlYduyJbxv7twwOnP37tDT1qNHCGRF4axobrGf/CRsIlVV0oKbu+8xsxHADMJUH4+5+0IzuwPIc/epwPXAI2Y2kjBQYXDC82rfBFYVDW6I1ARmRKEtgxDaHknWZxARkaCwMNyKXL8eJk4MtzA/+aT45333hUXCZ88OU1iUNHVqCG47d4aRmq1awdlnFwezVq3CeZdfHjYRKV2VXatURETCs2GffhpuUx57bOgBu/vu0LZ2beg9++QTuP32MPnr0qVhXrLMzDClxXHHhdn7hw+Hrl3DLc2XXgpTaNSpU/zz2GPDs2gicnBaq1REpArbsiXcsmzWLExHceGFIZStXRsWKQf4+c/h3ntDr9rvfx9GVR5zDOTkwFlnhYf+Idy+XLMmHKtWbd8/6+ijS5/LTETKh4KbiEgl8+KLMGcOvPcezJ8fZvnv1y/c4szKCvONNW0atiZNwtapU3jvkUeG25n7mwC2evWvjtIUkYql4CYikmaWLw+3LFesKN5q1SpeZPy228LD/iecAKeeGhYp7969+P1Tphz4+pq1XyR1KbiJiKSYDz+EBQuK17RcuTLc6pw+PRy/8UZ47rnwukaN8JzZqacWv3/ChDB1RtGM/iJSeSi4iYhUsMWL4eWXw0P/ReEsPz/0omVlwYMPwp/+FM6tWTMEs5ycsHxSRgb8z/+EZ9JycsJtzpLPmmlRGJHKS8FNRCSJ3GHJEnj1VRgwABo2hGnT4PrrQ0jLzg6jM886K8yBlpUFI0bAoEHhWKNGYcWARIm9ayJStSi4iYgcwPbtMHNmCGDHH1+8ruW2beG5spKhCsKEs88/D6+8EgLbmjWhvXlz6NMnPHM2YEDoLSvt/YkrAYiIJFJwExEpxdy5YU3MsWNh06bQdtVV8OijIcTVqRNuUdavD/XqhW3QILjmGigogCuvDM+ZnXNOWDXg3HOLb2E2aBDf5xKR9KbgJiIS2bo1TIcB8NOfwjvvwGWXhUBWv36YTBbCs2Z33RUC3WefhW3TpuLRmMcfH6bhOPnk0uc6ExH5urRygohUaXv2hJn+H3sMZswIU2s0bBgGEDRtGnrSREQqklZOEBEpoaAgrK/5xBPhGbRGjWDo0BDkoPhZNhGRVKLgJiKV0p498PbbYUHzpUvD9sEHYU3N4cPDvGh33w0XXwx/+Qt861thTjQRkVSm4CYiaWvGjDD/2dq1oddszRro0SNMtbF7N5x5ZhhIUL16eO7spJPCSE4Ic6CtWxdui4qIpAsFNxFJWf/+dxggMH8+vP9+CGmnnw7PPhuOX3kl/Pe/4XXDhnDssdC5c9ivVSsEu5ycMJqzeonfdhkZCm0ikn4U3EQkVrt3h9uY8+eHZZ5274Z77gnHrrsO8vJCwDrllDC1Rrduxe+dMSMMHmjSJKwwUNL551fMZxARqSgKbiJSYfbsCetwFj34/7OfwUMPwa5dYT8zE7p2LT7/8cfDnGdNm5Y+UW3HjsmvWUQklSi4iUjS5OfDrFmh12zOHHj3XdixI8x7Vq9euK35s5+FANahA5x44lcHCLRvH1/tIiKpSMFNRMrNpk0wZQr07h2m1/jHP8IIziOOgNNOg5/8BHJzQ88awBVXxFuviEi6UXATkcPyxRcwdWoYMDB9erjtOWZMGDjQr18Y5dm2bfGqAiIi8vUpuInI17ZhA7RoERZcb9YMRoyA/v1DrxqEtTobN463RhGRykTBTUTKZOtWmDkTJkwIAwWefDKM9rztNjjjjLBpXU4RkeRScBORAxozBh59FN56K0zV0aABfP/7YWJbM7jxxrgrFBGpOpL672Mz62VmS81smZmNKuV4CzObZWbvmtl8M7s4as8xs+1mNi/a/prwns5mtiC65v1mpU0SICKHqrAwjPq8554wuGDr1tC+cmUYCfrzn8PLL4dVCh54oPTpOUREJLnM3ZNzYbMM4APgfCAfmAMMcPdFCec8DLzr7g+ZWTvgRXfPMbMc4AV332cyADN7G/gp8BbwInC/u087UC25ubmel5dXPh9MpJKZNw/uuitM27FhQ2hr0wYmTw4/i3rWRESkYpjZXHfPLe1YMnvcugLL3H25u+8CxgN9SpzjQJ3odV1gzYEuaGZNgTru/h8PifNJoG/5li1SOX3+Obz0Ungm7fzzw0hQCKNA//Of0Mv25JNh7rXFi0NoA4U2EZFUksxn3JoBqxL284FuJc65HXjJzK4FjgTOSzjW0szeBTYDv3L3N6Jr5pe4ZrNyrlukUti7N0zB8dlncPbZYTkp9zCAoEOH8LwaQJcu8MknCmgiIukg7sEJA4Ax7n6vmZ0OPGVm7YG1QAt332BmnYEpZnbyoVzYzIYBwwBatGhR3nWLpKTNm+G550LP2fHHw9//HlYoOPFEuPRS6N49rPVZp07xexTYRETSRzKD22qgecJ+dtSWaAjQC8DdZ5tZFtDI3dcBO6P2uWb2EXBi9P7sg1yT6H0PAw9DeMbtsD+NSAp77TV45JHwXNr27XDCCXDJJeGYGUycGGt5IiJSTpL5jNscoLWZtTSzGkB/YGqJcz4BzgUws7ZAFlBgZo2jwQ2YWSugNbDc3dcCm83sG9Fo0kHA80n8DCIpa8GCMBIUwjJT06bB4MEwezZ88EEYBSoiIpVL0nrc3H2PmY0AZgAZwGPuvtDM7gDy3H0qcD3wiJmNJAxUGOzubmbfBO4ws91AIXC1u2+MLj0cGAPUAqZFm0il5w6LFoWA9tRTMH9+6Gk766ww4ODuu6FmzbirFBGRZEradCCpRNOBSDpyD/On1aoFH34IZ54J69aFY127wqBBMGBAmBBXREQqjwNNBxL34AQRibjDRx+F+dRmzQq9af37wx//CDk5cPHFYcH2nj2hZcu4qxURkTgouImkiC5dYO7c8PqYY0JA69Ej7GdmwuOPx1ebiIikBgU3kRgsWABjx4agNmNGGPk5cCBcdVUIbG3aaJoOERHZl4KbSAVZvRqefhqeeSYEt4wMuOAC2LIlzKs2cmTcFYqISKpL6iLzIlXdxo1h5QKAN9+EUaPgqKPgL38Ji7W/+OJXJ8MVERE5EAU3kXLmDv/6F/zgB9C0Kfz1r6H9kkvC4IN//xuuuQYaN463ThERST+6VSpSjh56CEaPhoULQ0/asGHFKxjUqgWtWsVbn4iIpDcFN5HD9OGH0Lp1eP1//xcC2t//HqbyOPLIeGsTEZHKRcFN5GvYuhXGjQu3Qd95J9wCbdkSnn1WYU1ERJJHz7iJHIItW8LyUsceC0OHws6d8MAD0KhROK7QJiIiyaQeN5FDsHkz/OEPYRWDkSPhjDM035qIiFQcBTeRA9i9Gx59FF5/Pcy/1qwZLF8OTZrEXZmIiFRFulUqUorCwhDU2rSBn/wEVq4MvW2g0CYiIvFRcBMpYelS6NQpzMNWuza88EKYl61u3bgrExGRqk63SkWAXbtCr1rr1pCdDfXqhVGjl18O1fTPGxERSREKblJl7d0L//xnCGjPPRdGhi5dGkaGvv563NWJiIjsS8FNqqQnnoCbbw7rhR55JPTtCwMGhOWqNEpURERSlYKbVAmLFoWetauuChPl1qsH3bqFsNa7NxxxRNwVioiIHJyCm1Ra7mFgwe23h9UNqlWDk04Kwa1Pn7CJiIikEz12LZXSnj1w9tnw7W+H1Q7uvx9Wrw4jRUVERNKVetykUlm5Eo47DqpXD6saDBwIP/whZGbGXZmIiMjhU4+bVAoffRRCWqtWkJcX2n73Oxg2TKFNREQqj6QGNzPrZWZLzWyZmY0q5XgLM5tlZu+a2XwzuzhqP9/M5prZgujnOQnveS265rxoOzqZn0FS29q1cM01YYWDyZPhppvg+OPjrkpERCQ5knar1MwygNHA+UA+MMfMprr7ooTTfgVMcPeHzKwd8CKQA6wHLnH3NWbWHpgBNEt430B3z0tW7ZIedu2C006D9eth6FC45RZo2jTuqkRERJInmc+4dQWWuftyADMbD/QBEoObA3Wi13WBNQDu/m7COQuBWmZW0913JrFeSRMLF0K7dlCjBjz4IJxyCpxwQtxViYiIJF8yb5U2A1Yl7Ofz1V4zgNuBH5hZPqG37dpSrnMZ8E6J0PZ4dJv0FjNNl1pV7NoFv/wldOgQ5mQDuPRShTYREak64h6cMAAY4+7ZwMXAU2b2ZU1mdjJwN/DjhPcMdPdTgB7RdkVpFzazYWaWZ2Z5BQUFSfsAUjEWLgwT5v7ud2GU6CWXxF2RiIhIxUtmcFsNNE/Yz47aEg0BJgC4+2wgC2gEYGbZwGRgkLt/VPQGd18d/dwCjCXckt2Huz/s7rnuntu4ceNy+UASj7//HTp3DvOwTZkS9mvXjrsqERGRipfM4DYHaG1mLc2sBtAfmFrinE+AcwHMrC0huBWYWT3g/4BR7v5m0clmVt3MioJdJtAbeD+Jn0FSwDHHwIUXwvvva7UDERGp2pIW3Nx9DzCCMCJ0MWH06EIzu8PMvh2ddj0w1MzeA8YBg93do/edANxaYtqPmsAMM5sPzCP04D2SrM8g8XCHp5+GP/857F9ySehpO1oTv4iISBVnISdVbrm5uZ6Xp9lD0sHGjXD11TBxYliy6tVXwxqjIiIiVYWZzXX33NKO6a9ESRmffBIGIEyZEgYhvPKKQpuIiEgirVUqKWH79tDDtnEj/POfcPrpcVckIiKSehTcJCXUqgW33hom0+3cOe5qREREUpOCm8Rq0SJYswbOOw8GD467GhERkdSm4Caxee+9ENjq1oXFiyEzM+6KREREUpse/ZZY5OVBz56QlQXTpim0iYiIlIWCm1S42bPh3HNDT9vrr0Pr1nFXJCIikh4U3KTCjRsXJtN9/XVo2TLuakRERNKHgptUmD17ws/77gu9bs2bH/h8ERER+SoFN6kQL74YpvpYtQoyMqBRo7grEhERST8KbpJUu3fDr38dFoc/4oiwiYiIyNej4CZJ89570LUr3H47XH55WHe0YcO4qxIREUlfmsdNkua3v4W1a2HyZOjbN+5qRERE0p+Cm5Sr+fPD7dATToC//CUsEq9eNhERkfKhW6VSLnbvhjvvhNxc+MUvQlvjxgptIiIi5Uk9bnLYFiwI64y+8w707w8PPBB3RSIiIpWTgpsclpdegt69oV49eO45+M534q5IRESk8tKtUjks3bvD8OGwcKFCm4iISLIpuMnXMm4cfP45HHkk/OlP4Xk2ERERSS4FNzlk48fD978Pf/hD3JWIiIhULQpuckhmzw4DEXr0gFtuibsaERGRqkXBTcrs44/D0lXNm4dJdWvWjLsiERGRqkXBTcrs6qvDfG0vvKD52UREROKQ1OBmZr3MbKmZLTOzUaUcb2Fms8zsXTObb2YXJxy7OXrfUjO7sKzXlOR57DF48UU46aS4KxEREamakhbczCwDGA1cBLQDBphZuxKn/QqY4O6nAv2BB6P3tov2TwZ6AQ+aWUYZrynlyB0mToS9e6FZMzj99LgrEhERqboOGtzM7Egzq5awX83MjijDtbsCy9x9ubvvAsYDfUqc40Cd6HVdYE30ug8w3t13uvvHwLLoemW5ppSjP/0JLr8cnnoq7kpERESkLD1urwKJQe0I4JUyvK8ZsCphPz9qS3Q78AMzywdeBK49yHvLck0AzGyYmeWZWV5BQUEZypWSpk6F668PE+sOGhR3NSIiIlKW4Jbl7l8U7USvy9LjVhYDgDHung1cDDyV2Lt3ONz9YXfPdffcxpod9pC98w4MGACdO4fetmoaxiIiIhK7svx1vNXMTivaMbPOwPYyvG810DxhPztqSzQEmADg7rOBLKDRAd5blmvKYdqzJ9webdgw9LodUV4xXURERA5LWRaZ/xkw0czWAAY0Ab5XhvfNAVqbWUtCuOoPfL/EOZ8A5wJjzKwtIbgVAFOBsWb2R+BYoDXwdvTnH+yacpiqV4dnnoFataBp07irERERkSIHDW7uPsfM2gBFk0AsdffdZXjfHjMbAcwAMoDH3H2hmd0B5Ln7VOB64BEzG0kYqDDY3R1YaGYTgEXAHuAad98LUNo1D/Ezy34UFsKsWXDuudCtW9zViIiISEkWctIBTjC7BnjG3TdF+/WBAe7+YAXUVy5yc3M9Ly8v7jJS3i9/Cb/7HbzxBpx5ZtzViIiIVE1mNtfdc0s7VpZn3IYWhTYAd/8MGFpexUlqePLJENqGDoXu3eOuRkREREpTluCWYWZWtBNNglsjeSVJRfvXv0Jg69kTRo+G4m9bREREUklZBidMB541s79F+z8GpiWvJKlIn38e5mk77jiYNAkyM+OuSERERPanLMHtJmAYcHW0P58wslQqgbp14b77oEsXaNAg7mpERETkQA56q9TdC4G3gBWEJafOARYntyxJtr174f33w+uBA+HEE+OtR0RERA5uv8HNzE40s9vMbAnwAGHONdy9p7v/paIKlOS44QbIzYWPPoq7EhERESmrA90qXQK8AfR292UA0XxrkuYefjgsHn/ddXD88XFXIyIiImV1oFul3wHWArPM7BEzO5ewcoGksZkz4Zpr4KKL4J574q5GREREDsV+g5u7T3H3/kAbYBZh6aujzewhM7ugogqU8vPJJ9CvX3iebdy4sLSViIiIpI+yDE7Y6u5j3f0SwqLu7xJGmkqaadYMrr0W/vGPMJpURERE0stBl7yqDLTkFezaBTU0bbKIiEjKO9wlryTNvfVWGITwzjtxVyIiIiKHQ8Gtktu9Oyxn5Q4nnBB3NSIiInI49Hh6JXfvvbBgAUyeDHXqxF2NiIiIHA71uFViH30Ev/41XHop9O0bdzUiIiJyuBTcKrEnngiLxj/wQNyViIiISHlQcKvEfv3rMCChWbO4KxEREZHyoOBWCW3YACtWgJkGJIiIiFQmCm6V0PXXw6mnwuefx12JiIiIlCcFt0rm1VfDs23XXKPVEURERCobBbdKZPt2+PGPoXVr+NWv4q5GREREypvmcatE7rwzTAEycyZkZcVdjZlcOEcAABHvSURBVIiIiJS3pPa4mVkvM1tqZsvMbFQpx+8zs3nR9oGZbYraeya0zzOzHWbWNzo2xsw+TjjWKZmfIV24w5YtcNVV0LNn3NWIiIhIMiStx83MMoDRwPlAPjDHzKa6+6Kic9x9ZML51wKnRu2zgE5RewNgGfBSwuV/4e6TklV7OjIL87UVFsZdiYiIiCRLMnvcugLL3H25u+8CxgN9DnD+AGBcKe39gGnuvi0JNVYKEybA22+H19X01KKIiEillcy/5psBqxL286O2fZjZcUBLYGYph/uzb6C7y8zmR7daa+7nmsPMLM/M8goKCg69+jSxahUMGQK33RZ3JSIiIpJsqdI/0x+Y5O57ExvNrClwCjAjoflmoA3QBWgA3FTaBd39YXfPdffcxo0bJ6fqFDBqFOzZA6NHx12JiIiIJFsyg9tqoHnCfnbUVprSetUALgcmu/vuogZ3X+vBTuBxwi3ZKundd2HsWBg5Elq1irsaERERSbZkBrc5QGsza2lmNQjhbGrJk8ysDVAfmF3KNfZ57i3qhcPMDOgLvF/OdaeNm2+GBg3gxhvjrkREREQqQtJGlbr7HjMbQbjNmQE85u4LzewOIM/di0Jcf2C8u3vi+80sh9Bj988Sl37GzBoDBswDrk7WZ0hlhYVw9tnQty/Uqxd3NSIiIlIRrEReqpRyc3M9Ly8v7jJEREREDsrM5rp7bmnHUmVwghyC6dNh/HjN2SYiIlLVaMmrNLN7N/z0p1CjBnz3u3FXIyIiIhVJwS3NPPYYfPghTJ0KGRlxVyMiIiIVSbdK08jWrXD77XDmmdC7d9zViIiISEVTj1sa+fOf4dNP4bnnwtqkIiIiUrWoxy2NtGkD114LZ5wRdyUiIiISB/W4pZHvfCdsIiIiUjWpxy0NrFwJv/89bNsWdyUiIiISJwW3NHDbbWFQwoYNcVciIiIicVJwS3ELFsCTT4a525o3j7saERERiZOCW4r75S+hbl0YNSruSkRERCRuCm4p7I034IUXQmhr0CDuakRERCRuCm4prHZt6NcvTAEiIiIioulAUlinTjBxYtxViIiISKpQj1sKcoff/AbWrIm7EhEREUklCm4paP58uOUWeP75uCsRERGRVKLgloLGjoXq1eG73427EhEREUklCm4pprAQxo2DCy+ERo3irkZERERSiYJbinnzTVi1Cr7//bgrERERkVSj4JZiliyBhg2hT5+4KxEREZFUo+CWYoYODaNJjzwy7kpEREQk1Si4pZBdu8LPGjXirUNERERSU1KDm5n1MrOlZrbMzPZZbdPM7jOzedH2gZltSji2N+HY1IT2lmb2VnTNZ82s0sScwYPhoovirkJERERSVdKCm5llAKOBi4B2wAAza5d4jruPdPdO7t4JeAD4fwmHtxcdc/dvJ7TfDdzn7icAnwFDkvUZKtIXX4R523Jy4q5EREREUlUye9y6Asvcfbm77wLGAwd65H4AMO5AFzQzA84BJkVNTwB9y6HW2D3/PGzbptGkIiIisn/JDG7NgFUJ+/lR2z7M7DigJTAzoTnLzPLM7D9mVhTOGgKb3H3Pwa6ZbsaOhebNoXv3uCsRERGRVJUqi8z3Bya5+96EtuPcfbWZtQJmmtkC4POyXtDMhgHDAFq0aFGuxZa3ggKYMQNuuAGqabiIiIiI7EcyY8JqoHnCfnbUVpr+lLhN6u6ro5/LgdeAU4ENQD0zKwqc+72muz/s7rnuntu4ceOv+xkqxBFHwF//Cj/8YdyViIiISCpLZnCbA7SORoHWIISzqSVPMrM2QH1gdkJbfTOrGb1uBHQHFrm7A7OAftGpVwJpvxT7kUfCj34EJ50UdyUiIiKSypIW3KLn0EYAM4DFwAR3X2hmd5hZ4ijR/sD4KJQVaQvkmdl7hKD2e3dfFB27Cfi5mS0jPPP2aLI+Q0VYtQpGj4ZNmw5+roiIiFRt9tW8VDnl5uZ6Xl5e3GWU6ve/h5tvhuXLoWXLuKsRERGRuJnZXHfPLe2YHoWP2dixcMYZCm0iIiJycApuMVqwIGyau01ERETKQsEtRmPHQkYGXH553JWIiIhIOlBwi9HKlXDhhZDis5WIiIhIikiVCXirpLFjYdeuuKsQERGRdKEet5gUBbYaNeKtQ0RERNKHglsMdu8Oo0jvuSfuSkRERCSdKLjF4OWXYc0arZQgIiIih0bBLQZjx0L9+mFggoiIiEhZKbhVsK1bYcoU+O539XybiIiIHBoFtwr2j3+E8KZJd0VERORQKbhVsDPOgD/8AXr0iLsSERERSTeax62CtWgBN9wQdxUiIiKSjtTjVoFmz4aJE2HPnrgrERERkXSk4FaBRo+GESOgmv6ri4iIyNegCFFBCgthxowwBYiCm4iIiHwdihAVJC8P1q+HXr3irkRERETSlYJbBZk+HczgggvirkRERETSlYJbBZk3D7p2hUaN4q5ERERE0pWmA6kgzz0Hn38edxUiIiKSztTjVkHMoF69uKsQERGRdKbgVgGuvx6uuy7uKkRERCTdJTW4mVkvM1tqZsvMbFQpx+8zs3nR9oGZbYraO5nZbDNbaGbzzex7Ce8ZY2YfJ7yvUzI/w+EqLISnn4aCgrgrERERkXSXtGfczCwDGA2cD+QDc8xsqrsvKjrH3UcmnH8tcGq0uw0Y5O4fmtmxwFwzm+Hum6Ljv3D3ScmqvTy9+y6sW6dpQEREROTwJbPHrSuwzN2Xu/suYDzQ5wDnDwDGAbj7B+7+YfR6DbAOaJzEWpNm+vTw88IL461DRERE0l8yg1szYFXCfn7Utg8zOw5oCcws5VhXoAbwUULzXdEt1PvMrGb5lVz+pk2Dzp3hmGPirkRERETSXaoMTugPTHL3vYmNZtYUeAr4obsXRs03A22ALkAD4KbSLmhmw8wsz8zyCmJ6wMwdunWDwYNj+eNFRESkkknmPG6rgeYJ+9lRW2n6A9ckNphZHeD/gP9x9/8Utbv72ujlTjN7HLihtAu6+8PAwwC5ubn+dT7A4TKDe++N408WERGRyiiZPW5zgNZm1tLMahDC2dSSJ5lZG6A+MDuhrQYwGXiy5CCEqBcOMzOgL/B+0j7BYVq+HPbuPfh5IiIiImWRtODm7nuAEcAMYDEwwd0XmtkdZvbthFP7A+PdPbFX7HLgm8DgUqb9eMbMFgALgEbAb5L1GQ6HO/ToAVddFXclIiIiUlkkdckrd38ReLFE260l9m8v5X1PA0/v55rnlGOJSTN/PqxZA2efHXclIiIiUlmkyuCESqdoGhDN3yYiIiLlRcEtSaZNg06doGnTuCsRERGRykLBLQk2b4Y331Rvm4iIiJSvpD7jVlXVqhVulbZoEXclIiIiUpkouCVBZiace27cVYiIiEhlo1ul5cwdfvMbeD9lZ5cTERGRdKXgVs4WLoRbboH//Ofg54qIiIgcCgW3cqZpQERERCRZFNzK2bRp0L49ZGfHXYmIiIhUNgpu5WjLFnjjDfW2iYiISHIouJWjJUvCVCAXXRR3JSIiIlIZaTqQctSlC6xfD9UUh0VERCQJFNzKWWZm3BWIiIhIZaW+oXKyZAmcfDLMnh13JSIiIlJZKbiVk2nTYNEiLSovIiIiyaPgVk6mT4c2bSAnJ+5KREREpLJScCsH27bBP/+p0aQiIiKSXApu5eC112DnTgU3ERERSS4Ft3LQsCEMHAg9esRdiYiIiFRmmg6kHHTrFjYRERGRZFKPm4iIiEiaUHATERERSRMKbiIiIiJpIqnBzcx6mdlSM1tmZqNKOX6fmc2Ltg/MbFPCsSvN7MNouzKhvbOZLYiueb+ZWTI/g4iIiEiqSNrgBDPLAEYD5wP5wBwzm+rui4rOcfeRCedfC5wavW4A3AbkAg7Mjd77GfAQMBR4C3gR6AVMS9bnEBEREUkVyexx6wosc/fl7r4LGA/0OcD5A4Bx0esLgZfdfWMU1l4GeplZU6COu//H3R14EuibvI8gIiIikjqSGdyaAasS9vOjtn2Y2XFAS2DmQd7bLHpdlmsOM7M8M8srKCj4Wh9AREREJJWkyuCE/sAkd99bXhd094fdPdfdcxs3blxelxURERGJTTKD22qgecJ+dtRWmv4U3yY90HtXR6/Lck0RERGRSiWZwW0O0NrMWppZDUI4m1ryJDNrA9QHZic0zwAuMLP6ZlYfuACY4e5rgc1m9o1oNOkg4PkkfgYRERGRlJG0UaXuvsfMRhBCWAbwmLsvNLM7gDx3Lwpx/YHx0WCDovduNLM7CeEP4A533xi9Hg6MAWoRRpMedETp3Llz15vZyq/5URoB67/meyW59N2kNn0/qUvfTWrT95O6Kuq7OW5/BywhL0kpzCzP3XPjrkP2pe8mten7SV36blKbvp/UlQrfTaoMThARERGRg1BwExEREUkTCm4H93DcBch+6btJbfp+Upe+m9Sm7yd1xf7d6Bk3ERERkTShHjcRERGRNKHgth9m1svMlprZMjMbFXc9VZ2ZPWZm68zs/YS2Bmb2spl9GP2sH2eNVZWZNTezWWa2yMwWmtl1Ubu+nxRgZllm9raZvRd9P7+O2lua2VvR77hno/k2JQZmlmFm75rZC9G+vpsUYWYrzGyBmc0zs7yoLdbfbQpupTCzDGA0cBHQDhhgZu3irarKGwP0KtE2CnjV3VsDr0b7UvH2ANe7ezvgG8A10f9f9P2khp3AOe7eEegE9DKzbwB3A/e5+wnAZ8CQGGus6q4DFifs67tJLT3dvVPCNCCx/m5TcCtdV2CZuy93913AeKBPzDVVae7+OrCxRHMf4Ino9RNA3wotSgBw97Xu/k70egvhL6Bm6PtJCR58Ee1mRpsD5wCTonZ9PzExs2zgW8Dfo31D302qi/V3m4Jb6ZoBqxL286M2SS3HRMugAXwKHBNnMQJmlgOcCryFvp+UEd2KmwesA14GPgI2ufue6BT9jovPn4AbgcJovyH6blKJAy+Z2VwzGxa1xfq7LWlLXolUJHd3M9MQ6RiZ2VHAc8DP3H1z6DgI9P3Ey933Ap3MrB4wGWgTc0kCmFlvYJ27zzWzs+OuR0p1pruvNrOjgZfNbEniwTh+t6nHrXSrgeYJ+9lRm6SW/5pZU4Do57qY66myzCyTENqecff/FzXr+0kx7r4JmAWcDtQzs6J/vOt3XDy6A982sxWER3LOAf6MvpuU4e6ro5/rCP/o6UrMv9sU3Eo3B2gdjeypAfQHpsZck+xrKnBl9PpK4PkYa6myomdyHgUWu/sfEw7p+0kBZtY46mnDzGoB5xOeQ5wF9ItO0/cTA3e/2d2z3T2H8PfMTHcfiL6blGBmR5pZ7aLXwAXA+8T8u00T8O6HmV1MePYgA3jM3e+KuaQqzczGAWcDjYD/ArcBU4AJQAtgJXC5u5ccwCBJZmZnAm8ACyh+TueXhOfc9P3EzMw6EB6gziD8Y32Cu99hZq0IvTwNgHeBH7j7zvgqrdqiW6U3uHtvfTepIfoeJke71YGx7n6XmTUkxt9tCm4iIiIiaUK3SkVERETShIKbiIiISJpQcBMRERFJEwpuIiIiImlCwU1EREQkTSi4iUiVZ2Z7zWxewlZui0abWY6ZvV9e1xORqk1LXomIwHZ37xR3ESIiB6MeNxGR/TCzFWb2v2a2wMzeNrMTovYcM5tpZvPN7FUzaxG1H2Nmk83svWg7I7pUhpk9YmYLzeylaAUDEZFDpuAmIgK1Stwq/V7Csc/d/RTgL4TVVAAeAJ5w9w7AM8D9Ufv9wD/dvSNwGrAwam8NjHb3k4FNwGVJ/jwiUklp5QQRqfLM7At3P6qU9hXAOe6+3MwygU/dvaGZrQeauvvuqH2tuzcyswIgO3F5IjPLAV5299bR/k1Aprv/JvmfTEQqG/W4iYgcmO/n9aFIXGdyL3q+WES+JgU3EZED+17Cz9nR638D/aPXA4E3otevAj8BMLMMM6tbUUWKSNWgf/WJiETPuCXsT3f3oilB6pvZfEKv2YCo7VrgcTP7BVAA/DBqvw542MyGEHrWfgKsTXr1IlJl6Bk3EZH9iJ5xy3X39XHXIiICulUqIiIikjbU4yYiIiKSJtTjJiIiIpImFNxERERE0oSCm4iIiEiaUHATERERSRMKbiIiIiJpQsFNREREJE38fzPZzxCLKYTJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "HISTORY : \n",
            "<tensorflow.python.keras.callbacks.History object at 0x7f39cc01db90>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "aVLQWhcubqaj",
        "outputId": "3aeff38a-7f51-4c82-eeaf-a120a9e999e1"
      },
      "source": [
        "# SKEWED CASE\n",
        "distribution = \"SKEWED\"\n",
        "fed_x , fed_y = split_data(distribution, num_clients)\n",
        "fed_x = np.array(fed_x)\n",
        "fed_y = np.array(fed_y)\n",
        "\n",
        "server1 = Server(num_clients, distribution, load_weights=False)\n",
        "server1.init_clients()\n",
        "server1.model.summary()\n",
        "server1.train_slaves(learning_rate, batch_size, local_epochs, federated_rounds)\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(lr=learning_rate)\n",
        "server1.model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"TEST SET EVALUATION\")\n",
        "print(server1.model.evaluate(test_x , test_y))\n",
        "visualize_metrics(server1.history)\n",
        "\n",
        "print(\"HISTORY : \")\n",
        "print(server1.model.history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-09c068c293b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfed_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mserver1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mServer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mserver1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_clients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mserver1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'distribution', 'edge_interval', and 'global_interval'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3WT1huq2jfe"
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(lr=learning_rate)\n",
        "server.model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "a = server.model.evaluate(test_x , test_y)\n",
        "history = server.model.history\n",
        "print(a)\n",
        "print(history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkcIGsJd2jh4"
      },
      "source": [
        "# server.train_slaves(0.001, batch_size, local_epochs, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L73YfswG2jj-"
      },
      "source": [
        "# IMBALANCED CASE\n",
        "distribution = \"FIXED_SIZE_BALANCED_DATA\"\n",
        "fed_x , fed_y = split_data(distribution, num_clients)\n",
        "fed_x = np.array(fed_x)\n",
        "fed_y = np.array(fed_y)\n",
        "\n",
        "server2 = Server(num_clients, distribution, load_weights=load_weights)\n",
        "server2.init_clients()\n",
        "server2.model.summary()\n",
        "server2.train_slaves(learning_rate, batch_size, local_epochs, federated_rounds)\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(lr=learning_rate)\n",
        "server2.model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"TEST SET EVALUATION\")\n",
        "print(server2.model.evaluate(test_x , test_y))\n",
        "visualize_metrics(server2.history)\n",
        "\n",
        "print(\"HISTORY : \")\n",
        "print(server2.model.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-aGYxcVA6uz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbnkuKDU2jmW"
      },
      "source": [
        "# a = getModel()\n",
        "# a.compile(optimizer=tf.optimizers.SGD(), loss=\"sparse_categorical_crossentropy\")\n",
        "# a.fit(train_x, train_y, epochs=1, shuffle=True, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggm6WPxI2jov"
      },
      "source": [
        "shapes = [\n",
        "          [784, 10],\n",
        "          [10]\n",
        "]\n",
        "aa = np.array(server.model.get_weights(), dtype=object)\n",
        "\n",
        "def flatten_weights(weights, shape=shapes):\n",
        "  flat_ = []\n",
        "  for layer in weights:\n",
        "    flat_ = tf.concat([flat_, tf.reshape(layer , [-1, ]) ] , axis=0)\n",
        "  return flat_\n",
        "l = flatten_weights(aa)\n",
        "\n",
        "b = tf.Variable(l, trainable=True, dtype=tf.float32)\n",
        "\n",
        "tf.norm(b)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}